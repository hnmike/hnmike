---
title: "DataExpert.io - Week 4 Homework Flink & Kafka - Data Engineering Bootcamp"
author:
  - "Jade Codes"
published: 2025-01-03
source: "https://www.youtube.com/watch?v=tcBPjWMpqW4&t=3256s"
image: "https://i.ytimg.com/vi/tcBPjWMpqW4/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgZShlMA8=&rs=AOn4CLAwJNOot1nb4wf6ra7QK95ACE17VQ"
created: 2025-03-23
tags:
  - "youtube"
  - "flink_kafka"
  - "data_engineering"
  - "data_aggregation"
summary: "Data Engineering Bootcamp Week 4 homework review focusing on Flink & Kafka. Aggregating data by IP and host using session windows and SQL queries."
---
# DataExpert.io - Week 4 Homework Flink & Kafka - Data Engineering Bootcamp

![DataExpert.io - Week 4 Homework Flink & Kafka - Data Engineering Bootcamp](https://www.youtube.com/embed/tcBPjWMpqW4&t=3256s)

> [!summary]- Description
> Thank you for joining me on my Data Engineering Bootcamp journey!
> 
> I'm so excited to have you here as we work through this incredible free bootcamp together. A huge shoutout to Zach for creating such an amazing resource!  
> 
> Before we dive in, let’s go over a few quick house rules:  
> 1️⃣ If you’re also following along with the bootcamp, make sure you check out the official site at:
> https://bootcamp.techcreator.io/ 
> 2️⃣ Don’t forget to watch Zach's videos directly too! He deserves the watch hours, and you deserve the credit for completing the bootcamp.  
> 
> This bootcamp is completely free, but I also want to let you know I’ll be joining Zach's paid bootcamp in January. 
> 
> If you're interested in leveling up your skills even further, you can use my link for 20% off: 
> https://www.dataexpert.io/jade
> 
> Thank you again for being here, let’s make the most of this bootcamp and learn some amazing skills together!
> 
> Music Playlist:
> https://www.youtube.com/playlist?list=OLAK5uy_nkZOhFjdiR0bICR-qsgNJRueOmHUT2ALQ
> https://www.youtube.com/watch?v=BTLCJGfkIaw

> [!note]- Transcript (Youtube)
> for hello everyone welcome to today's stream we are going to be going through the homework for the Flink um the Flink the the stuff that's been done on Flink this week and so that's the thing that we're going to be starting on now um so if we have a look here we have this homework this task here which is to create a flint J that seizes the input data by IP address and host and um it wants us to use a 5 minute Gap and we want to answer the following questions what is the average number of web events of a session from a user and Tech Creator compare the different results between different hosts so Zack wilson. Tech Creator .io Zack wilson. te. and lulu. creator. so what we need to do is we probably just need to do something very very similar to what is done in the aggregation job and start job where we um where we get the data from from cfare we then aggregate it by uh by the IP address and by the host and then we get this information every 5 minutes basically so the way that we're going to do that is we are going to look at what has been done in both here and in the aggregation job so as you can see here what what's done is we we first create a process process events s Kafka which basically will create the IP the event time the refer the host the URL the Geo data the window time stamp and everything that has been do as part of the the collecting the the data of the IP addresses for the um for for the for the a lotted window and then here we do a created aggregate event sync pogress which is basically what is been done here which is You' got your event hour you've got your host and you've got your number of hits so if we have a so so the biggest difference between this and what we're going to do is this will get us our like event hour and host and our number of hits but we need um to do we need to do aggregation by not by number of hits we want to do it by IP address so again if you look here you can see here there's we've got a like Group B which is Group by um host uh and the window and then we also but but instead of doing Group byy by host we want to do group buy by host and by IP so that's going to be the biggest change that we need to do um so so so that'll be what what we end up doing so similarly this we need to have the initial um the initial start job which will be the the job that um gets the initial initial data in okay so what I'm going to do is I'm going to do I'm going to create a aggregated host IP job here and what I'm going to do is I'm going to do very similar to what we've done for the aggregation job so there's going to be a lot of code that I can reuse but I'm not going to reuse all of it so the the first thing that I'm going to use is I'm going to create the um processed events source using using what we what's been used for capka we need to take all of this in here as well so what this is doing is it's going to create a it's going to use the ca key in the cap capka secret what we've got then we've got a table name which is the process events capka and this is going to create a um the the source the The Source table and then what we're going to do is we're going to have the table create all of this information IP event time refer host URL geod data window time stamp and water mark for window time stamp as is a window um time stamp and then it's just going to have an interval of every 15 seconds um and this is just to make sure that we don't have like duplicate events and then and then that's going to connect to the basically create the connector to to capka once that's done so again we can copy a lot of this here this is just meup we don't need both of these either we just need one one example so the previous one was using had two separate examples one was for getting information about the event hour the host and the number of hits whereas the second one was getting the the information about refera as well and we don't actually care about um refera so what we can do is instead of having refera here we can have IP here instead and then similarly here we can change this to IP as well um then I'm not sure if that should be the right name about event hour cuz if you think about it it's not going to be every hour it's going to be every 5 minutes so I'm not sure if that's the correct name for it um but that's the biggest change that we've made here is the call the change to column IP here the next thing we need to do is we want to create a create aggregated events on IP sync Pro process and actually what I'm going to do is I'm also going to change this to IP just cuz this one's there okay and then what we're going to do is similarly to what we do here which is going to be create creating an aggregated events referer what we can do instead is we can do a uh we can change this to IP I'm just going to have a look again what time stamp three means as well I think we might I think we might need to change this one \[Music\] okay so it just um just asking chat what it does it's a data type that stores a date time with a fractional second Precision of three digits so uh it will do that okay okay that's fine um because we're only doing um this every 5 minutes it will make marginal difference really okay so we've got our table which has the event hour um should be our event iteration maybe maybe I might get my down for submitting it like this rather than having event hour we'll see I think it feels like that's the right thing it should be called I don't think it should be called the vent hour um or window yeah let's call it that event window time stamp and then we can then create our table in post so that's the first thing we need to do so for okay so if we just log in okay so is Docker not winning it okay that's why so if I go into my Docker it's not winning this so what we can do is we can create our table name which I'm going to create um aggregated IP sauce aggregated then in here we can change this to IP as well okay so that's been created now so we've got our event winner time St we got our host we got our IP and we've got a number of hits hi lemine hey okay so now we've got that what we can do is we can call this here um and then we can change this to IP sync table um and then we can say okay well we want to make this as a aggregation here so we've got our group by we've got our um select we've got our um execute and set um and then we've got our weight what I'm going to do is just for just for the purposes of making it quicker I'm going to make the tumble over window one minute and then when I submit it it's going to be 5 minutes but that just allows us to have a little bit more data rather than having to wait every 5 minutes to get that dat in uh the only thing that I am thinking at the moment is so one thing I'm going to do is I'm just going to run um go back to Docker I'm just going to run this again and I'm just going to open this up just takes a bit of time to open up I think I am indeed how are you uh how are you finding the pro Progressive are you are you doing okay so this is just going to allow me to connect it to the cluster again okay so if I just um set the time stamp here to today to now you can see that there's a lot of messages that are here which is good okay so we have messages coming through we can start um so this is what we these are the two fields that we care about basically um they're the things that we're going to be aggregating on uh if anyone is interested on getting this UI for Apache Kafka all I did was um in the previous lab I went to um Let me show I went to this open source um perus CF UI which is pretty cool and I just I just ran this locally this this locally which allowed me to access this through Local Host and then I just added the the um the Capa details in there to log in so that I could then just verify that I could get that data you don't need to do this but this was just for me to be like okay is where's the data getting getting pushed to so from what I understand I'm pretty sure that Zach already has a ruining job that does this already and we're just basically querying that data that's already there there and creating our our our aggregated data from it so this has already been done by Zach and we just need to get this data and we just need to query this data yeah okay okay so so I'm pretty happy with my job now I'm I'm happy that it's doing what I want it to do um we've got our assour we've got our aggregated IP sync we then insert that into our we we insert the uh this into our aggregated syn table and we just need to run this then basically so what I'm going to do is I'm just going to do a make down make sure that I've not got anything running so let's just go into and I'm also just going to add to my make file here as well I'm just going to add a avigation IP job okay so now we've got our container is running we can do the make aggregation IP job and so now we just need to let it run for about 5 minutes just so that it creates those tumbling windows and gets the aggregated data each minute per like before what I'm going to do is actually I'm going to like visit a couple of these sites as well let's go to the homework I'm just going to keep bashing these you know just going to verify that it's not dangerous for people to know what might be dresses e be fine should be fine so that job's running now and if I go into um where do I go what's the I've forgotten I've completely blanked on the part number for Flink uh this one okay so that's running fine and it's getting events from the processed the source and it's putting things into our processed event IP aggregated table so now we should be able to do a uh select perfect so as you can see here this is like literally running every minute um now so once we should be able to do another keep doing this and this is updating every minute clearly there's some sort of delay cuz this is a minute before but um but it's working which is great so we'll wait another minute and make sure that it's doing it again okay so let's do it again yeah so again that's putting it again which is good it's it's working um so that's that's that's that's what we want to see so now we've got it working I'm just going to stop um so one thing I'm questioning is is it says to answer these questions but how do I answer those questions like how do I submit that that's not clear to me uh so what I'm going to do is I'm going to stop my job and then I'm going to change this to 5 minutes and I'm going to empty the data and then we're going to wait for like 10 minutes to get that much data that we need okay so I think it he probably wants us to write a a p spark um oh yeah P spark is it is that is that what he wants us to write what I might do is to get a bit more clarity on that is I'll ask a question in the the group so that's running now I'm just going to do another select here okay okay no no right I'm going to stop that so what we need to do is we need to do make down and then once we've done our make down we can then delete from okay okay and now we can make up and then we can start the job again just make sure that I've definitely added a five made it five minutes now I'm also going to make sure that it's definitely deleted yeah there's no more data in there perfect and then we going to do the aggregation again okay so that's going to take some time again so whil that's you know working I'm going to play Snake there's terrible on it e we've got 10 minutes we need to kill basically so I'm just going to do this if anyone wants to ask any questions SC all it there was the corner ones that are really hard to play let me have a look now how is it go why is it not working maybe it's just now let me try I'll wait another minute and then I'll try again for right is it working now yes perfect okay so I'm just going to wait another 3 minutes now and then maybe we can do some stuff with it B of that now i' got a really short attention span I get bored quite easily so what we're going to do is first thing I'm going to ask chat GT is I'm pretty sure that means two P's back I'm Prett s that's right okay I'm just going to do uh select query then cuz pretty sure what is the average number of web events of a session from a user on Tech creator okay for so what I'm going to do is I'm going to I am doing get aage row hits per session and so I'm doing select IP host and average number of hits as average number number of hits for events process average and then I'm do going to do a group by by I'm going to get rid of this as well we don't need to do that I'm going to do a group by IP and Hurst then cast as that right what's the cast syntax again I can't remember I've forgotten already let's go to the skill Scripts just going to have a look at my previous homework \[Music\] what yeah okay that's fine okay so that basically gets you the um average number of hits per IP address and host which is the we going to here that's the homework one of web events so is that what's the average number of web events of a session from a user on Tech creator so do we need to do where Tech Creator where first I don't like I think it's that I think that's the syntax yeah so I don't know if he wants it to be boot camp. Tech Creator and. or if he wants it to be um or if you want it to be like the just like Tech creator. but I'm assuming he wants any Tech creator. event so I'm just going to add that there and if if I get my down bar for it then I get my down for it but um but yeah okay and then we'll do this as well um for for I don't know if this is right by the way we're going to see if I get marked down for it or anything but this is what I assume he wants how he wants this F it so I'm going to answer it like this and if it's wrong then we'll just have a look at what the llm says and like edit the feed based on the feedback given where the other little water see okay so I think that's fine to answer like that so what I'm going to do is I'm going to create um two two files I'm going to zip them so I I'm going to ask Zach what he wants me to do with these if he wants me to make them unlisted then I will do if he is happy for me to leave them public then I will do he's always been really chill with me having them but um yeah whatever he I'm going to be guided by him basically um and and see what he says I think I think to be honest like the biggest thing for him is going to be the fact that like that once he makes it private and stuff then there's not really a lot you can do with this information like you can do this homework but you can't submit it anyway you can't do anything with it so it doesn't really matter if you've got access to it do that make sense it's like um so so does it really matter that much I don't know but but I'll be guided by what what Zach says basically so I'm going to do is I'm just going to create a new file two files in here I'm going to create a um I'm going to put this in there and I'm going to also put my job in here then I'm going to zip this filer for okay so now if I go to data expert I uh I don't know if I'm going to this is going to be right it was a very loose um assignment so I might get a fail but at least if I submit it I'll get some direction on what it is I need to submit if it's wrong but let's see for this this UI is not the best nothing's done at the moment so have the assignment stopped or something this might be what someone was mentioning earlier okay so I'm wondering if um either one there's something wrong with the site like like there's something wrong with chat the op integration um to it's just not ready yet um but let me see if there's any provided template \[Music\] no so that that didn't actually give me anything that just said this assignment link here which just takes me to the homework okay so it has come back um so I've got a grade C which is fine um thank you for submitting your assignments I'll provide feedback and various components of your submission based on the requirements your script demonstrates a solid attempt to Aggregate and we by IP and host okay um 5 minute Gap rather than a five minute fixed interval that's fine um okay that's fine so what we can do is we can change the session to be a 5 minute gap between sessions rather than a tumbling window uh session window should be implemented to respect the 5 minute activity between sessions which is different from using epic to fine um cool we can do that okay so what I'm going to do is I'm going to do pie Flink I'm going to ask Chad about this as well using uh instead of \[Music\] window suggest one of the things I found quite hard about like the homework is that the I find the instructions quite vague I don't know if anyone else has found that so hopefully there's something similar to Tumble over but it's not um Okay cool so instead of doing tumble window we should be able to do session with gas this um this music reminds me a bit of um Emily for e this one another thing that really annoys me right is take this group demonstrates a solid attempt to aggregating web events by IP and host however the deviation from that that time code quality well structured however using consistent comments SI stock screens to explain more complex or essential pathway impementation would improve readability and maintainability but like this wasn't in the the original like ex lab so it's like well pot caring cut black kind of thing just say just say all okay so we do need to correct the this as well um the assignment focus on sessions but the SQL provided groups by uh so maybe I need to do one um one of the SQL scripts here a session from a user what is the average number of web events of a session from a user on Tech Creator okay post and event window time stamp as well we need to do it by event window time stamp there we go yeah okay that should be right we'll do the same here as well okay that's fine let's run this again me to do that whilst I'm doing that whil that's running what I'm going to do is I'm going to comment it create create m honestly I really hait I I really don't like putting comments in um that I like this for for I'm just using um gbt this I would never usually put this level of com comments in there um but but um chat gbt oh the llm asked um me to do that I just think they're noisy for I might create a read me file actually as well I'll put this in a read me file um yeah I'm going to put this in a read me file \[Music\] group y okay I think that's everything that we need so um I'm going to put that in the read me file I'm going to do is I'm going to open up um don't know why I think there's a BG there but I'm going to open up um that was big on it for there honestly like this saves so much time just getting Chachi with right stuff for you so good I love it for okay so I'm just going to add those in just realized as well that um that last music I've been playing isn't worldy fre and hopefully I'm not going to get told off for using it okay so what we're going to do is for for \[Music\] \[Music\] Okay so we've got that done I'm going to do is I'm going to delete my previous one I'm going to just check everything's right and then let's compress I assume I'll at least get a B now because I've done the correct session but we'll see for for for oh for taking a bit of time to do this um feedback okay I'm going to give it another few minutes and if it's not done it in a few minutes then we'll call it here for tonight and we'll see where it is like tomorrow because this is taking its time never usually takes its time it's usually been really quick previously going to make down as well just so that that can stop ruinning cool so it has passed it's got Grade B I'm going to read what the feedback is um okay so it wants us to include specific SQL theories tailored to compare sessions for hosts Zach Tech Creator uh consider a step through or verification process to ensure PL job andc scripts achieve this desired sessionization and analytics goals effectively cool so what I'm going to do is because we've got our Grade B which is a pass for now what I'm going to do is I'm just going to finish there I love that best regards your name um but I will Implement that feedback tomorrow uh so that we can get that completed but um that's what I've done so far and like I said I think the um the llm is pretty good and giving feedback in in terms of what to do so it it should be relatively easy to do that include specific SQL squares um so does it want me to do okay right that's fine maybe it just wants me to do that then like uh where yeah this is probably going to have absolutely no data in yep doesn't matter on so I'm just just adding those various SQL queries in there okay I'm going to leave that for now then um we've got our B it's all we needed well I say I'm going to leave it I'm going to just submit this and if I don't get if if it doesn't have an na now then I will I'm also going to update the read me to chat file uh question instruction \[Music\] for I really hate documentation I don't know if any realized that but yeah then the last thing I want to do is um just see okay okay so what I'm going to do is I'm just going to test that this still works fine okay so let's do make up okay that's running F so all we've done since the previous one is we have added the read me we've added some more instructions on how to run the SQL queries we've added the additional queries here with some data and we have that is it basically so again let's zip that and if this is still a b then I'm going to call it there but yeah e for okay so I'm just going to cancel this job again for is it going to work is it going to work okay so I think it took about 5 minutes last time to get the answer so hopefully it'll be quick I'll be soon that we get the answer is like more like um what's the word uh what's the word you know when you waiting for something and it's got you on edge what's that word um edgy got get got you more edgy than um then when you're wanting something like terraform or a pipeline like is it going to work is it going to work is it going to be is it going to be right who knows hey how are you okay so I'm going to end pretty much here anyway okay so so we've got everything passed again now it's just uh and show the SQL focus and specific host for accurate comparison the inadequacies in addressing the best HSE in your queries needs attention okay so because I put data expect. there it didn't like that for some reason um so what I'm going to do is I'm just going to remove that and then I'll I'll probably try and get the job running for a little bit longer tomorrow so these sites get hit at least um and then once I've done that I can then I can then fill it up with the appropriate data uh but yeah um I think that's just because yeah it wants me to be a bit more specific it wants me to only focus on the ones that that um it's told me to so that's fine I can do that um um but yeah um that's it uh I'm going to end there thank you for for watching me for everyone who's watched and yeah I'll see you next time byebye


 > [!info]
> - **Homework Task (2:21):** Create a Flink job that sessions input data by IP address and host, using a 5-minute gap.
> - **Objective (2:34):** Determine the average number of web events per user session and compare results across different hosts (zackwilson.techcreator.io, zackwilson.te, lulu.creator).
> - **Code Reuse (7:20):** Reusing code from aggregation jobs but modifying it to aggregate by IP address and host.
> - **Key Modification (10:11):** Changing the aggregation from number of hits to IP address. This involves modifying the column in the table schema.
> - **Table Creation (15:09):** Creating a table in PostgreSQL to store the aggregated data, including event window timestamp, host, IP, and number of hits.
> - **Session Window Implementation (11:52):** Implementing a session window with a gap of 5 minutes between sessions, rather than a tumbling window.
> - **SQL Queries (50:16):** SQL queries to answer the homework questions about average web events per session from a user on Tech Creator.
> - **Addressing Feedback (1:46:03):** Include specific SQL queries tailored to compare sessions for hosts Zach Tech Creator.
> - **LLM for Guidance (1:46:50):** Using the LLM for feedback and guidance on what to do.
> - **Specific SQL Queries (1:47:12):** Adding additional queries focusing on specific hosts to address the feedback.
> 