---
title: "ELK Stack Mastery: Building a Scalable Log Management System"
author:
  - Cey's Data Hub
published: 2024-11-04
source: https://www.youtube.com/watch?v=U1i5sIZzEQM
image: https://i.ytimg.com/vi/U1i5sIZzEQM/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYACtAWKAgwIABABGFcgXShlMA8=&rs=AOn4CLARvheDX6AM_05frKE1wIdx8UlGlA
created: 2025-03-20
tags:
  - "#youtube"
  - ELK
  - Stack
  - Management
  - Data
  - Engineering
summary: Learn how to build a scalable log management system using the ELK Stack (Elasticsearch, Logstash, Kibana) on Debian-based virtual machines. Perfect for data engineers!
---
# ELK Stack Mastery: Building a Scalable Log Management System

![ELK Stack Mastery: Building a Scalable Log Management System](https://www.youtube.com/embed/U1i5sIZzEQM)

> [!summary]- Description
> Overview:
> In this comprehensive tutorial, you'll learn how to set up a secure, multi-node Elasticsearch cluster across three Debian-based virtual machines using VirtualBox. The step-by-step guide covers resource allocation, network configuration, SSH setup, and the complete installation of Elasticsearch, Kibana, and Logstash.
> 
> What You'll Learn:
> 
> Configuring Virtual Machines in VirtualBox with varying resources and roles for efficient performance.
> Setting up SSH connections for seamless management of VMs in headless mode.
> Installing and configuring Elasticsearch on a multi-node cluster with role-specific nodes.
> Performing secure password management and browser-based verification of Elasticsearch nodes.
> Setting up Kibana and Logstash for log management and monitoring, including index lifecycle policies for data retention.
> 
> Resources:
> 
> GitHub Repository: https://github.com/akarce/elk-stack-mastery
> Medium Blog Post: https://medium.com/towards-data-engineering/elk-stack-mastery-building-a-scalable-log-management-system-7adc64313336
> LinkedIn: https://www.linkedin.com/in/akarce/
> GitHub: https://github.com/akarce
> 
> Join the Community:
> If you enjoyed this content, please LIKE and SUBSCRIBE for more tutorials and insights on data engineering, infrastructure, and DevOps topics.
> 
> Tags:
> Virtual Machine Setup, Elasticsearch Cluster, VirtualBox, Debian, Kibana, Logstash, Data Management, Multi-Node Cluster, SSH Connections, Elasticsearch Configuration, Data Lifecycle Policies, Technical Setup Guide.
> 
> Hashtags:
> \#DataEngineering \#VirtualBox \#Elasticsearch \#Debian \#ClusterSetup \#VMManagement \#TechTutorial \#Virtualization \#LogManagement \#DataInfrastructure

> [!note]- Transcript (Youtube)
> for this tutorial we've prepared three virtual machines using virtual box running debian-based operating systems let's go through our specific configuration our machines elk test 1 elk Test 2 and Elk test 3 have been allocated different resources based on their roles for the hot and cold data nodes we've assigned 8 GB of RAM each while our Frozen data node receives 6 GB storage wise we've provisioned 40 GB for two machines and 50 GB for the third to ensure Optimal Performance we've configured four CPUs for the hot and cold nodes while the Frozen node operates with three CPUs SSH server configuration to optimize our resource usage we'll be running these VMS in headless mode and managing them through SSH connections this eliminates the overhead of graphical user interface rendering on our host machine we'll need to install open SSH server on both our VMS and our WSL environment to enable this functionality system preparation let's begin by accessing root privileges using the Su command we'll then run a series of commands to set up our SSH server AP get update apt get install open SSH server system CTL start SSH system CTL enable SSH after executing these commands we need to modify our VM network settings navigate to the network section and change from natti to bridged adapter this change is crucial for enabling proper network connectivity we'll then reboot the machines to apply these changes to verify our network configuration we'll use the IP add R show command to obtain our IP addresses establishing connectivity with our IP addresses in hand we can now establish SSH connections we'll use the command syntax SSH username at IP address to connect to each machine you'll need to authenticate using the password we configured during the initial VM setup once connected we'll switch to the root user to ensure we have the necessary permissions for our upcoming configurations elastic search installation process after organizing our terminal windows for efficient management we'll proceed with the elastic search installation first we need to install curl using app install curl this tool is essential for securely downloading and verifying our elastic search gpg Keys package configuration in this part of the setup we're configuring the system to install elastic search directly from elastics official repository ensuring we're using secure and verified packages first we're adding a gpg key from elastics repository next we're adding the elastic search repository to our systems list of sources this repository is where the latest elastic search packages are maintained after adding the repository we run an update to refresh the list of available packages including the newly added elastic search options finally we install elastic search this process sets up the main components and dependencies required to run elastic search on this system once installation finishes the system will generate an initial password for the default elastic user this password is essential for the initial setup so make sure to save it securely although you'll be able to change it later having access to this initial password is crucial as we configure elastic search further next we'll configure the first elastic search node to set up our cluster first we'll start elastic search on this machine Machine by running a command to initialize the service with elastic search running we can now move on to editing the main configuration file known as elastic search. yml where we'll adjust settings specific to our cluster setup we'll set a unique cluster name which is like an identifier for our cluster next we Define the node name which will identify this specific machine within the cluster we'll also specify the role of this node by assigning it the roles of Master and data hot we're setting it up to manage critical cluster functions and handle data storage tasks according to our projects needs we'll adjust the network settings so that the cluster is accessible over the network by setting the host to 0.0.0.0 and configuring the port to 92000 the standard port for elastic search we're leaving other settings like the security configurations and data and log paths at their default values as they're already optimized for this setup these changes form the foundation of our cluster and prepare this first node to interact with additional nodes that will configure in the following steps verifying node configuration to ensure our first node is set up correctly we'll run a couple of commands to test the connection we'll start with with a quick command to check that elastic search is up and responding this command bypasses certificate verification and uses the elastic username along with the autogenerated password from the security configuration stage this will give us a response showing essential details about our elastic search instance like the node name cluster name unique cluster identifier version info for a more secure connection test we'll use a command that references a specific certific ific at file you'll still enter the elastic user's password when prompted but this method helps keep your password hidden in your terminal history next we'll set a new password for the elastic user to improve security for this we navigate to the directory where elastic search binaries are stored and use a reset password tool this utility allows us to choose a new password in a secure guided process let's verify our configuration through a web browser open your browser and enter the following URL start with https followed by your virtual machine's IP address then add Port 920 since we're accessing this from our host machines browser remember to use your virtual machines IP address enter the username elastic along with your newly set password you should now see the same cluster information we previously viewed using curl review our configuration file it's named elastic search. yml and is located in the ETC elastic search directory third restart the service by typing system CTL restart elastic search let's check our cluster's health in your browser enter https your virtual machine's IP address Port 92000 followed by uncore cluster Health at this point you'll only see our initial node listed as we haven't added the other nodes yet we need to generate enrollment tokens from our first node elk test one navigate to the USR share elastic search bin directory and enter this command elastic search create enrollment token - S node we'll need to run this command twice once for each node will be adding make sure to save these enrollment tokens carefully they contain crucial information for expanding our cluster second node configuration we'll move to our second virtual machine and begin the node configuration process first navigate to the elastic search binary directory Second Use the enrollment token from our first node to reconfigure this node enter the command elastic search reconfigure node followed by two dashes and and the word enrollment token then paste your enrollment token third when prompted confirm the reconfiguration now we'll modify the elastic search. yml file for our second node we need to uncomment and modify specific lines to configure this node as our cold data node here are the settings to change set cluster. name to match our existing cluster set node. name as elk Test 2 set node. rolls as data uncore cold for our tiered architecture configure network settings set network. host to 0.0.0.0 and http.sys start the elastic search service on elk Test 2 by typing system CTL start elastic search let's enroll our third node first generate a new enrollment token from our first virtual machine run elastic search create enrollment token DS node switch to your third virtual machines terminal navigate to the elastic search directory and enter elastic search reconfigure node followed by two dashes and the word enrollment token then paste your new enrollment token let's verify our cluster's health open your browser and refresh the cluster Health page if our second node has joined successfully you'll see the number of nodes has increased to two for a more detailed view check the nodes API by entering https your virtual machine's IP address Port 92000 followed by underscore nodes this gives us comprehensive information about our cluster setup to analyze this data more EAS easily copy the Json output and paste it into Json pathfinder.com this tool will help us examine important details like host names node names and roll configurations third node configuration let's continue configuring our third node when prompted to continue the reconfiguration process type Y and press enter next we'll edit the elastic search. yml file using the Nano text editor we need to mod ify and uncomment several crucial settings the key configurations include set our cluster name to Elk test cluster Define the node name as elk test 3 assign the role of dataor Frozen configure network settings to allow external connections \[Music\] troubleshooting and cache configuration if you encounter an error when starting the elastic search service don't worry this is expected for Frozen nodes we need to specify a cache size add the following line to your yml file xpac do searchable snapshot. shared. siiz followed by 30% after saving these changes and restarting elastic search the service should start without errors cluster verification let's confirm our setup refresh the cluster Health page once more you should now see three nodes listed in the cluster the nodes API will show detailed information about all three nodes including their names IP addresses and assigned roles installing additional components we'll enhance our setup by installing key kabana on our first virtual machine and log stash on both our second and third VMS here are the commands we'll use for Cabana on vm1 type apt install Cabana DY for log stash installation on Virtual machines 2 and 3 enter apt install log d-y note that installation times vary Cabana needs about 340 megabytes and log stash needs about 430 mbes file access setup to give log stash access to elastic search logs add the log stash user to the elastic search group on your second virtual machine with pseudo user- a elastic search log stash this lets log stash read and process the elastic search log now let's set up the log stash pipeline create a configuration file using Nano customize the cluster name for your setup using Nano followed by Etc logc conf. d/ then your cluster name followed by Das logs.com the configuration needs two main parts the input setup will watch Json log files in the elastic search log directory read from file Beginnings use JS n for parsing the output setup will connect to all three elastic search nodes using https create daily indices with the pattern elk test cluster logs DD setup authentication and SSL certification on the first virtual machine with kibana set up secure access reset the Cabana system user password with kibana Kiana's configuration file with Nano Etc kibana kb. yml change these settings port to 5601 allow connections from any IP set elastic search hosts \[Music\] configure Authentication disable SSL verification for the demo e troubleshooting you might see issues during cabana's first setup it needs a data content node for default indices which our cluster doesn't have yet if you get a cabana login error and see a red cluster status check these things check Shard allocation in your browser with https your vm's ipor cat shards for allocation details check https your vm's ipor cluster allocation expain question mark the error will show that shards can't be allocated because we need nodes with the data content you might see issues during cabana's first setup it needs a data content node for default indices which our cluster doesn't have yet let's fix this by modifying our first nodes configuration go back to your first virtual machines terminal and edit the elastic search. yml file to add the data content rooll after saving your changes we'll need to restart both services enter these commands system CTL restart elastic search then system CTL restart Cabana to verify our fix refresh theore cat shards page you should now see all shards in the started State the allocation explain page should show there are no unassigned shards in this cluster in indicating we've successfully fixed the issue now we access the Cabana and setup ilm policy can access Cabana through your web browser log in using the elastic user and your chosen password follow these steps click explore on my own from the welcome page navigate to the management section in the left pane select index management under the data section now let's set up our index life cycle management policy to handle data retention across our tiered architecture open the console tool and will create a comprehensive ilm policy that will handle hot data for the first 10 days with a 40 GB size limit move data to the cold tier after 10 days optimizing storage with Force merge transfer data to the Frozen tier after 20 days for long-term retention after executing this policy configuration you'll see a 200 okay response with acknowledged true confirming successful creation you can review and modify this policy any time through the index life cycle policies section in the left navigation pane in The Next Step we'll be creating index template to Define how our indices should be structured open the Management console let's create this template using the putut command in the console this template configuration matches indices following our cluster's naming pattern sets up one Shard and one replica for each index Associates are previously created life cycle Poli policy establishes a rollover Alias for seamless index transitions let's continue by returning to our virtual machines to configure the log stash pipeline first we'll reconnect to our third virtual machine using SSH once connected will switch to the root user by typing Su followed by enter moving on to our second virtu ual machine we need to modify the log stash pipeline configuration we'll focus on changing the index naming pattern in the output section currently we have a static index name that looks like your cluster name followed by Dash logs we're going to make this more Dynamic by adding data information the new pattern will be your cluster name followed by Dash logs Dash and then the date in year month and day format this change is important because it allows our system to automatically create new indices based on the dates in our log files which helps with data management on our second virtual machine Let's Start The Log stash service type systemctl start log stash and press enter to check if it's running properly enter system CTL status log stash to verify the index creation open your web browser and navigate to the Cabana interface go to the index management section you should see a new index that contains about 175 documents look at the life cycle section of this index it will show you which phase it's currently in and how it's progressing through our life cycle stages remember this index will move to the cold phase when it either reaches 40 GB or becomes more than 10 days old now we need to configure log stash on the third VM let's move to our third virtual machine first check log stashes current status by typing system CTL status log stash now we'll copy the configuration from our second virtual machine on the second VM view the configuration by typing cat followed by Etc logstash conf. d/ and then your cluster name followed by Dash logs.com take this configuration and create the same file on the third virtual machine once you've copied it over start log stash by typing systemctl start log stash now now let's set up our data views in Cabana one go back to Cabana and refresh the index management page two create a new data view for our indices three configure the index pattern to match how we're naming our log files four to handle any pattern matching issues will create an empty index that matches our pattern set up an alias to combine our indices configure the data view with the correct pattern name this setup will help us analyze data across all our indices while maintaining proper life cycle management exploring index documents let's look at the documents in our index go to the Discover view in kibana you'll find several fields in our log documents including timestamps version information error messages and their types log levels host names before verifying our pipeline give the pipeline some time to process the logs you'll notice the number of documents increasing as logs from both our second and third nodes are processed all this data is being stored in the hot tier on our first node which we're accessing through kibana let's check if log stash is installed on our first virtual machine by typing system CTL status log stash Dash since it's not installed we'll install it by typing app install log stash followed by-y after installation we need to one add log stash to the elastic search Group by typing pseudo user- a elastic search log stash two create a pipeline configuration file that matches our other nodes three start the log stash service learn verifying data ingestion first let's verify our data pipeline is working correctly open your web browser and navigate to the Cabana interface go to the index management section and refresh the page several times you should notice the document count increasing click through to the Discover view of your index you'll notice many new Fields have appeared in our data since these are different Json files they contribute various unique fields to our index look at the left sidebar and find the analytics section click on dashboards we're going to build this dashboard completely from scrp scratch so click create visualization before we begin double check that you're using the correct data view it should be the one we created earlier let's create several visualizations to help us understand our data Marsh records metric let's start with a simple metric one look for the records field in the available Fields list two drag it to the center of your workspace this will be our foundation three from the visualization types select Legacy metric click save and return into your dashboard timestamp distribution now let's visualize our data over time one create a new visualization two find and drag the timestamp field to your workspace three choose the bar horizontal stacked visualization type four add a breakdown by virtual machine name this will show different colors for each VM five adjust the time frames to match your analysis needs six save this visualization and return to the dashboard Trace ID analysis for tracking our operations one create another visualization two find and drag the trace. id. keyword field to the center three select the donut visualization type important look for the advanced section in the right panel five find and disable the option that says group remaining values as other this default setting can make our data harder to understand six save and return to the dashboard log file path distribution to understand where our logs originate one create a new visualization two locate and drag the log. file. path. keyword field into your workspace three keep the default bar vertical stacked style it works well for this data four save and return to the dashboard logger information for a detailed view of our logging sources one create another visualization two select the log. logger do keyword field three choose the donut visualization type four again disable group remaining values as other in the advanced settings the default setting can obscure important details five save and return to the dashboard log level distribution let's analyze our log severity levels one create a new visualization two drag the log. lev. keyword field to the workspace three select the pie chart Style four this visualization will reveal that the majority of our logs are infol Level messages approximately 7 and 1 12% are warning messages a small fraction about 3% are error messages five save and return to the dashboard thread analysis finally let's examine our process threads one create your last visualization two use the process. thread. name. keyword field three choose the table visualization type five modify the settings to display only the top six values five save and return to the dashboard finalizing the dashboard make sure to save your entire dashboard to preserve all your work one of the most powerful features of this custom dashboard is its interactive drilling capabilities you can click on any element in any visualization to dive deeper into that specific aspect of your data for example clicking on a specific log level in the pie chart will filter all other visualizations to show only data from that log level this interactivity makes it easy to analyze patterns and investigate any anomalies in your cluster's behavior and that's it you've now set up a complete elk stack for comprehensive log management and Analysis this powerful system will help you centralize your logs gain valuable insights and and monitor your infrastructure more effectively I hope you found this tutorial helpful and informative remember the key to getting the most out of the elastic stack is continuous learning and experimentation if you enjoyed this video be sure to subscribe to my channel for more Tech tutorials and projects you can also follow me on medium GitHub and Linkedin to stay up to dat with my latest content and connect with me thank you all for watching and I'll see you in the next one take care


 > [!info]
> - **Multi-Node Elasticsearch Cluster Setup (0:00):** Learn to set up a secure, multi-node Elasticsearch cluster on Debian VMs using VirtualBox.
> - **Resource Allocation & Network Configuration (0:07):** Allocate different resources based on VM roles (hot, cold, frozen data nodes) and configure network settings for proper connectivity.
> - **SSH Setup for Headless VMs (0:41):** Run VMs in headless mode and manage them through SSH connections to optimize resource usage.
> - **Elasticsearch Installation & Configuration (3:31):** Install Elasticsearch from the official repository using secure and verified packages.
> - **Node Configuration & Verification (5:54):** Configure the first Elasticsearch node, set a unique cluster name, node name, and roles (Master, data hot).
> - **Password Management (8:05):** Set a new password for the elastic user to improve security.
> - **Cluster Health Verification (9:22):** Verify cluster health through a web browser and the cluster Health API.
> - **Node Enrollment (9:43):** Generate enrollment tokens from the first node to add additional nodes to the cluster.
> - **Cold & Frozen Node Configuration (10:08, 12:45):** Configure the second node as a cold data node and the third node as a frozen data node.
> - **Troubleshooting & Cache Configuration (13:32):** Specify a cache size for frozen nodes to avoid service startup errors.
> - **Kibana & Logstash Installation (14:54):** Install Kibana on the first VM and Logstash on the second and third VMs.
> - **Logstash Pipeline Setup (16:00):** Configure the Logstash pipeline to access Elasticsearch logs and create daily indices.
> - **Kibana Configuration (16:42):** Set up secure access to Kibana and configure authentication.
> - **Data Content Node Fix (20:00):** Add the data content role to the first node to fix Kibana login errors and red cluster status.
> - **Index Lifecycle Management (ILM) Policy (21:13):** Set up an ILM policy to handle data retention across tiered architecture (hot, cold, frozen).
> - **Index Template Creation (22:03):** Create an index template to define how indices should be structured.
> - **Logstash Pipeline Configuration (22:33):** Modify the Logstash pipeline configuration to use a dynamic index naming pattern.
> - **Data Views in Kibana (25:34):** Create data views in Kibana to analyze data across all indices.
> - **Dashboard Creation & Visualization (29:17):** Build a custom dashboard with various visualizations to understand data.
> - **Interactive Drilling Capabilities (34:40):** Use interactive drilling capabilities to analyze patterns and investigate anomalies.