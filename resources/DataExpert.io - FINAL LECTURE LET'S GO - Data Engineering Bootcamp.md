---
title: "DataExpert.io - FINAL LECTURE LET'S GO - Data Engineering Bootcamp"
author:
  - "Jade Codes"
published: 2025-01-31
source: "https://www.youtube.com/watch?v=Rl07R8asoaE"
image: "https://i.ytimg.com/vi/Rl07R8asoaE/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGCMgZShGMA8=&rs=AOn4CLDLCtVQc7S8IDuQSDYgOdeMfdw6Ig"
created: 2025-03-23
tags:
  - "youtube"
  - "Data_Engineering"
  - "Tech_Debt"
  - "Pipeline_Optimization"
summary: "Final lecture of a data engineering bootcamp covering identifying and addressing tech debt, optimizing pipelines, cloud cost management, and on-call best practices."
---
# DataExpert.io - FINAL LECTURE LET'S GO - Data Engineering Bootcamp

![DataExpert.io - FINAL LECTURE LET'S GO - Data Engineering Bootcamp](https://www.youtube.com/embed/Rl07R8asoaE)

> [!summary]- Description
> Thank you for joining me on my Data Engineering Bootcamp journey!
> 
> I'm so excited to have you here as we work through this incredible free bootcamp together. A huge shoutout to Zach for creating such an amazing resource!  
> 
> Before we dive in, let’s go over a few quick house rules:  
> 1️⃣ If you’re also following along with the bootcamp, make sure you check out the official site at:
> https://bootcamp.techcreator.io/ 
> 2️⃣ Don’t forget to watch Zach's videos directly too! He deserves the watch hours, and you deserve the credit for completing the bootcamp.  
> 
> This bootcamp is completely free, but I also want to let you know I’ll be joining Zach's paid bootcamp in January. 
> 
> If you're interested in leveling up your skills even further, you can use my link for 20% off: 
> https://www.dataexpert.io/jade
> 
> Thank you again for being here, let’s make the most of this bootcamp and learn some amazing skills together!

> [!note]- Transcript (Youtube)
> like look into congrats on getting to the end of the day one lecture if you're taking this class for credit make sure to switch to the other tab so you get credit for it okay there's essentially four things here that I think are going to be your big signals at the highest level of we are we have Tech or too much Tech de in data engineering we have uh pipelines breaking we have uh Cloud bills then we have a large Cloud bills that are maybe out of control Cloud bills you also have multiple sources of truth it's another interesting Tech de problem then you have unclear data set that are aren't documented so each one of these has their own kind of like remedies to kind of fix we're going to go over kind of some interesting remedies that we can go over for each one of these buckets so that we can know how to maybe fix some of the stuff okay say you have a painful pipeline you have a pipeline that's breaking and say it's break every on call so you have an on call and then it's like every Saturday and Sunday it breaks and it ruins the on calls we get and then it's like then you just you just dread being on call because you're like I have to give up my weekend and I don't want to do that because like a lot of times like if you're on call and it's the weekend and you have to work on the weekend and then you get no break and then you have to go immediately into work after working on the weekend you're like data engineering is freaking me out right now man I don't want to do it and so uh that's where uh troubleshooting these problematic children in these problem pipelines can be very important so the only thing you know I like this the only thing better than optimized is deprecated I love that saying because it's like that's how you the efficiency right is like you just delete the PIP doing I've not managed to get twitch set yet but I think I'll get it I I don't think I see much point in getting it set up for the stuff that I've been doing with the DAT engineering but I think when I start doing other things in streams that's an not it set up for it just doesn't feel right to just uh like start data like when i' I'm pretty much at the end I've I've got I've only got the homeworks left to do so but yeah I'll I I think I've got some time tomorrow to have a look at how I can uh set my my twitch up you save the most in the cloud oh nice when do you finish right if you just the pipeline doesn't exist um obviously that's not always the case of what you want but um so sometimes optim deprecated is the right play uh I want to talk real quick about an example that I had at Netflix that was interesting so when I was working on Netflix I worked in detection right and so detection they had this like Legacy system for detection that was based on it was a bat process Legacy system it was like an hourly bch processing Legacy system and uh it ran I mean there was like it was like a suite of like 50 pipelines that were all running to like detect anomalies in the cloud environment and uh the security team was like this isn't good because it detects anomalies an hour late and uh we were like yeah that kind of makes sense that makes sense why that's not good and then like we were like okay we're going to we're going to move some of them to streaming we going to move uh whatever we can to streaming and uh but then we realized that like even before we moved everything over to streaming we recognized that they weren't even using the data anyways so we were like why are we paying this maintenance cost every single day on these plus pipelines for data that's not even being used data that's not providing any value like why are we even doing that so um uh like so what we did so do you like um do you multitask then while you're watching this just like just have this on in the background whilst you're doing it was we got everyone into into a room and we were like can we get rid of this do we even need this like this is causing us a lot of headache do we even need to have these pipelines around anymore and uh there was a lot of push back because there was essentially the like what if like what if we need to run a query and then uh we we we we talked with them and we're like you haven't run a query in the last 60 days so that what if is like maybe that's not like actually gonna happen obviously security is an interesting space right because it's like you you want that you you only need the data when like something bad happens right so it's like a lot of times like maybe I love that so do I'm I'm I I love body doubling it's just so much better that's why I um do my streams just because it's so much easier to to do this when I'm talking to the people um it's kind of idea here uh so uh that was something that we ended up doing there we actually were able to convince them uh it took like like a six month process of convincing them to delete these pip lines but we were able to do it and that made our lives a lot better because then our the maintenance burden for the on call dropped like it went from like yeah I um I to be fair I wish I could go to jam streams more but a lot of the time it's during um it's it's during the work day and I I typically like keep my I've got my work laptop and I I've got my regular laptop and I keep I typically keep all of my content creation stuff on my personal laptop rather than my work laptop and so it tends to be quite separate on call being terrible to on call like almost being nothing and so a lot of times that could be the case and there was like because the thing was those pipelines were already as optimized as they could be there was nothing else we could do to make those pipelines better it just that there was a lot of them and that like they were doing a lot of work and that like once like you kind of have the uh um tragedy not traged comms you have the um Murphy's Law or something like that like where once you have enough of something you're guaranteed to have one bad bad of that right it's like once you have a room of enough people right you're guaranteed to have at least one like just guaranteed right because like that's just how people work or there's a certain percentage even if it's like one percent or half a percent like once you have enough people they guaranteed that there's going to be at least one in that room and so um same perspective here right where it's like okay well well like maybe we shouldn't try to spend all of our time and effort optimizing these pipelines but we should actually uh just delete them and in that case it was actually the right call and so uh like that's one of the things that you got to remember about especially when you inherit pipelines and they weren't necessarily pipelines that you built yourself but you inherit a suite of pipelines from another team or another engineer like question the value and actually ask yourself like is this worth being on the on call rotation is this something that should actually be troubleshooted over the weekend because maybe it's not um though I imagine like whenever the difficulty is I think when you take on someone else is could you always think you can write it better and then you start trying to write it and then you realize actually no I can't write better um or like you make your own like decisions what aren't necessarily the best decisions so yeah and maybe it shouldn't even exist and if that's the case then deleting it is great because then your on call becomes way easier and like I I'm sure some of y'all like are like Zack that sounds like kind of uh like too good to be true or like because I I think all of us have had nightmares as data Engineers where we were like you know our life would be a lot easier if we just deleted all the pipelines and then there would be no data and then and then our lives would be solved and then we wouldn't have to do anything and then all the all the buzzing in our head and all the anxiety in our hearts would go away and uh but like um in in some cases I've actually had a couple cases in my career where that that was the that was the call so um is there anything that can be done uh with this right besides you know deleting it uh you can migrate to new technologies it's great uh you can uh maybe Implement better data modeling so you have fewer pipelines that are running because you have more robust data modeling where like you don't have to have like duplicative models and you kind of have like one model or one pipeline that produces a more robust model because then it's like if you can take say you have a suite of 100 pipelines and there's a 1% chance that things break then that means that something's gonna break every day but if you havein and there's a one% chance things are going to break that means that things are going to break like a couple times a month and big difference very big difference like especially if you can keep the failure rate the same and you can make the modeling better and like uh uh the consistency which your things actually fail because things are going to fail pipelines fail like and like nothing's perfect and don't ever expect to write a pipeline it's never going to fail like it's going to fail and and and it's just about like the frequency and the rate and all that stuff that you want to think about right other things that you might want to consider when you have a painful pipeline is can you bucket bucket the table that can sometimes help quite a bit I I'll talk more about some examples that I've had in my career where bucketing was like a silver bullet and the other one is sampling sampling is great um uh a lot of time a lot of times you just need directionality you don't need all every single record and if you can just like get a 1% sample then you just get a 100x reduction in the complex of that Pipeline with like one CH mind and sometimes that's the solution just don't process all the data like I know these Solutions seem like in some ways they're not like tackling the scale they don't sound sophisticated but they're smart that's the part of it that's great is that like if because if you have like a bunch of pipelines that are processing a lot of data and they're not providing that much value and they're causing you a lot of headache like this is a beautiful path forward that can actually work and especially in terms of Maintenance and I've seen this work many times and uh definitely remember that deleting the pipeline could potentially be a tool in your tool bu you don't have to just optimize it so that's a beautiful path forward I love it so uh I'm sure some of y'all have upgraded from h spark it's probably a common thing that y'all have done uh I've seen massive gains here but there's also like it's interesting because this promise is not uh linear or not uniform right because a lot of times like some people are like oh if you migrate from hive to spark and you uh you'll see a massive performance gain and that's only in the case of very specific uh types of pipelines and they have to like essentially use like a very high cardinality group bu or a high cardinality join you have one of those two keywords in your sequel then migrating from hive to spark you're going to see a massive massive gain like probably between 50 to 90% um more efficient and uh like that's that's awesome I think one of the things here that some data engineers make a mistake about is they promise more because they think that that's going to be the case for every pipeline but some pipelines you're going to see flat some pipelines are going to be uh only five or 10% more efficient uh and then but there are some there are some edges is where it gets really really a lot more efficient where the being it because Spark versus Hive are very interesting because Hive does everything like on disc it doesn't have any it doesn't use Ram at all like blows my mind that that's what we did for so many years we're just gonna write all our data to dis forever and but in the same vein though because Hive does everything on dis it's very resilient and like um a lot like Hive might be really slow because it does everything on disc but it's definitely gonna um finish whereas spark might actually fail like that's one of the other things I I noticed when I did some hi to spark migrations is it was spark was more efficient but less reliable we like uh spark is actually more prone to out of memory exceptions and more prone to skew than Hive is um so when you do these migrations sometimes like it's a trade-off it's not just like you're you're getting it's not it's not like an upgrade it's uh like you're getting a certain set of traits but you're losing other sets of other set of traits and for the most part the trade-off is worth it and that's why people do the migration but that's what I'm saying is that like high pipelines are technically more reliable they're more reliable but less efficient so that's a thing to remember and the main reason for that is because they do all the calculations on dis whereas spark uses ramp and uh that can be one great way to improve the kind of efficiency of your pipeline and uh and the landing time and all sorts of other things like that but not necessarily the reliability right because the reliability is the one side that like Hive and sparker um like Hive is actually has a slight Edge so that's one thing you can do upgrade the technology another thing another option here right is maybe uh you want to move to like streaming or you want to move the pipeline to streaming obviously that should be something that should be taken very like you should be thinking through that problem very a lot like definitely like don't just bring in Flink like you should only be bringing in Flink after like you've really really thought about it and that's really the only thing that you should do right it's not necessarily like an upgrade problem that's more of like a I need to solve a new use case problem but in some cases streaming can actually be more reliable because of the fact that it's just processing data as it comes in as opposed to processing some big batch of data and then that can make it so that uh the memory footprint of the job can actually be more consistent and you don't have these big spikes in the memory footprint and uh because when you have a job that has big spikes in the memory footprint that's when you have jobs that are more likely to run out of memory and uh especially like in spark right there was that hard limit right you have that 16 gigabytes right where it's like if you have a partition that ends up being bigger than 16 gigabytes for whatever reason because of skew or whatever other reason then uh it's going to be more unreliable than um a streaming job that potentially won't have that same Spike because of the fact that it processes the data as it comes in so that can be another potential thing that could uh increase the reliability of your pipelines so uh technology upgrades pretty cool so sampling I love sampling uh I want to talk a little bit about an example uh kind of War story from my time at Netflix so um one of the things I worked on Netflix was how to create a metric that measured the uh the amount of incremental AWS cost from an AB from an AB test so it's like say you have two uh like a test and control group in an AB test and one of them causes the app to make more requests to the server and then that server will send more data down but maybe like it's 10% more requests so then the server the server load is 10% more or something like that and so like the way that I I was looking at that originally was like okay I'm just going to look at all the network requests that um that Netflix receives and it's like that's a very big data set that data set is hundreds of terabytes an hour and um and the metric that we were like the and if you're processing hundreds of terabytes an hour that's millions and millions of dollars a year in cost like an actual cost to the company so and our metric that we were making was probably not going to save that much money so like we realized that like okay like there's an Roi here where it's like we need a sample you like cut the data down and maybe only we ended up using I less than 1% and uh and since we were able to cut down the volume and because we only need the directionality of the of the sampling and or of the of the data not the whole like data set for auditing and so that's a good um way to do it uh before you set up sampling though uh make sure that you don't just like R like just set up whatever sample thing you want to do I think it really depends so like it probably like a lot of Zach's course is talking about companies that are quite large like um like Netflix and stuff so sometimes they want if they want like instant metrics over the last few hours then they probably do care uh but for the majority of companies they probably don't they probably have pry happy with the fact that it might take half an hour to run this is something where you do want to consult a data scientist about the data shape so that like because it's very important to get a random sample but for example here is another thing to think about with um like requests I think this is a beautiful example where like I think as data Engineers this is isn't something that we think about that much but like okay there's two ways that you could sample the uh the the requests right where it's like you could take a small percentage of all the requests and just do randomly take a percentage of all the requests or you can take their requests for a small percentage of users and then then you get the whole flow for every user but you only take a small number of users or do you just take a small number of all the requests across the board and those are you could get the same percent you could get the same like reduction but it's all about like what rows you pick and what rows you filter out and that makes a very big difference on the data set itself and like what you're trying to solve for like for example in this case uh the better solution here was to pick users and get the full request history for individual users not filter to like random random uh requests across the board because then uh you get the full kind of makeup of like the whole like request flow for each user and that's a better um aggregation model than like in this other case where it's like you have like one request for this user two requests for this user and it's like kind of like you don't have their full history so like the analytical capabilities of that way of sampling versus the other way of sampling is significantly different so that's where like don't just like be like like because it's easy to sample very very easy to sample like it's a oneliner to put that in the sampling but um don't like uh don't do that like make sure to ask a data scientist like that's my main point there unless you are amazing at statistics and you already have the data science skills then maybe do it yourself but I know I don't that's one of the things that I I recognize that I want to defer to a data scientist about because that will make um the whole process a lot better so remember sampling is another beautiful tool in your tool belt if your pipelines become more unreliable and you don't need the full data set okay but like when should you not sample I think this is another important question yeah but I think sampling isn't necessarily about about the time it takes it's about the the amount of data that you're storing as well it's not just about how long it takes but it's also the amount the amount that of storage that it takes so if they're storing petabytes of data then I guess it makes sense that they want to try and reduce that uh there's a good example here of like um if you need the entire data set for auditing purposes or whatever then sampling is not going to work because you're you might be looking for a needle in a h stack and if you sample then the needle is gone and like not going to find all the needles that you are looking for so audit purposes no no no okay so that's sampling audits don't work go to the next one bucketing bucketing is very important I'm going to give a couple examples of when I used bucketing in my career that have just mind boggling mindboggling how good they were right so um uh big thing with bucketing right uh is so when you have a join right so if you imagine you have a joint of two data sets uh you have this big thing called Shuffle right where you can imagine you have like the left and right side of the joins and then um how it works is the join key that join key gets hashed into a number and then that number gets moduled which is like you divide and you take the remainder and then that is the partition that that row gets assigned to and mostly this is done with um like the modulo the default moduo in spark is 200 because you want to have 200 partitions and then that's how it works uh the problem with a lot of this stuff is that you that whole process of slicing all the data up and moving it around and then moving it across and then matching it up is very very expensive that shuffle operation is very expensive so what you can do instead is when you write the data sets the left and right side say you say they both have user ID they're joining on user ID then uh you can write the left and right side data sets to their own partitions essentially so instead of writing like one big parket file you write like maybe a24 smaller paret files that do that modulo operation already so that you have them in 1,24 files and then and then the right side is also in 1,24 files so when you do the join you just match up the files right and then the files just match up and then you don't have to do all this crazy there's no Shuffle Shuffle doesn't exist if you if You Buck so and that is uh I highly recommend listening to the speaker series with Sundar uh he's a a senior staff data engineer at Apple and he talks a lot more in detail about how he uses bucketing to solve hyperscale problems at Apple at the paby scale so bucketing is one of the most important uh optimization techniques especially for the highest volumes of data because once you have massive massive volumes of data that join where it does that shuffle technique that shuffle Shuffle is broken like once you're over like 10 terabytes Shuffle is Shuffle just breaks down and becomes very very very expensive so that's where you can get a massive performance gain if you just write both of the left and right side of the join two bucketed tables because then you can do the join without Shuffle and it's very performant and so when I was at Facebook this is a big thing I was doing in notifications was I had the same problem where like uh the notifications table I had like this so one of the tables was called a notive data features which was like um it was a like a machine learning table that had for every notification it had the um like a vector of features of all the different features of that notification like when it should be sent what content type it was the probability that someone this feels very similar to previous week uh cuz we went through a lot of these Concepts in the previous week going to click on it the probability that someone was going to ignore it like all sorts a different um uh like a big Vector of like hundreds and hundreds and hundreds of things right and then on the other side you have the actual events you have the oh they clicked on it they sent it right because you need to merge these two data sets because then you have the features and the facts and if you merge them together then you can actually train the model again because then you're like oh we predicted that there was going to maybe drop the next time they generate a notification that's like that notification it's going to drop it a little bit because that's going to retrain it but anyways that join was actually at the notification level right because you're joining the notification features and the notification facts you join them together and then like that join was very very large and so what I did in that case was you join on notification and on user and if you do that then um and it was bucketed on user so then you just line up all the files that are based on the user ID and bucketed and then you can join those together and then uh that removes all the shuffling that was in there before and then that made that made that job uh go from taking so before that job was taking up 25% of all of notifications comput and then after I made the optimization it took up 4% so we got a massive massive increase in uh efficiency and also a ton of compute back and it made it so our name space was actually like working again it wasn't just like on fire all the time and so that was a big win that we were able to do with bucketing so um I highly recommend just checking out bucketing as well like we're going to do a little bit of bucketing um next week in the spark week if uh yeah because you're on in the infrastructure so y'all definitely be in the spark week so uh it's good stuff like I definitely have used it a lot I've used it at um at at Netflix as well and some other very hyper skill use cases uh so that's kind of like uh another big thing that I would recommend looking into there are drawbacks though I think that I want to talk a little bit about how like it's not like um like because just because it solves these hypers scale problems like I'm not advocating that every table I don't know about you but I'm totally up for eating the last slice of cake I'll happily take it off people's hands the last slice of cake the last slice of pizza yep bring it my way I am happy happy to take that off everyone's hands be bucket it and one of the main reasons for that is that say you bucket everything to 1,24 files and it's like a small table then when you read it it has to it has to read in 1,24 files and there's like opening and reading that many files is slope and like it's worth it when the when there's a lot of data but like if it's not very much data then the cost of like opening and reading all those files is is higher and more of a pain in the ass than if you uh just don't bucket so that's why like this is something that you is kind of more reserved like for tables that are over at least over a terabyte like I would not recommend bucketing on anything under a terabyte so that's uh that because if it's under a terab you might as well just Shuffle and you're going to get like probably a better performance characteristics so that's bucketing bucketing can save your life okay so another big thing that can happen another big signal for Tech debt right is a large Cloud bills so um one of the things to remember about the cloud is there's essentially three places that you pay you pay in IO you pay in compute and you pay in storage those are the three places that you pay um with IO usually being the biggest one and because the main reason why IO is the biggest one is compute is generally fixed right because you like rent your computers on like a fixed basis and then like you either have enough or you don't have enough and then if you don't have enough you need to buy more computers and great but like if you don't have enough Oran if you have up then like you're going to pay the same amount anyways and then storage is just generally really cheap like especially in comparison to IO and compute um and one of the things one of the ways you can think about that is okay uh move so moving data around and moving it from point A to point B is going to be one of the most expensive operations that you going to have in your Cloud bill this is where like uh one this is probably the one argument that I have for uh the signal table pattern if y'all remember from week three we talked about the difference between write audit publish and the signal table pattern and this is going to be my and this is Facebook's rationale as well of why they use signal table over the write audit publish is because write audit publish actually does a partition exchange so that means that every time that you write a table with write audit publish you actually essentially do two times you do IO twice right you do IO into staging and then IO from staging to prod right and so that's where you get you pay your IO cost twice which is pricey not cheap like it's actually one of the it's like the most expensive part of your Cloud bill so um that's where that's why it's not as cut and dry of like you should use right audit publish or you should use signal table because of the fact that IO is just so expensive so expensive and uh that was one of the things that I noticed like because when I was working um uh at Airbnb and I found some massive wins uh in storage and compute uh for Airbnb when I was like Computing the savings that I I I saved for them it was like essentially it was like okay I was able to save like five like 5% of all the savings was in storage and then 10% was in compute and then 85% was in IO and obviously this depends on the pipeline as well because the in that case the reason why that was the case for me is because the pipeline I was working on had a lot of Downstream usage so if I was able to make the the storage footprint of a table that has a lot of other pipelines reading it then that's actually where you get the big win the big uh savings is where they read in that smaller table every day and as opposed to reading in a bigger table every day and then then your the savings you get is multiplied by the number of Downstream pipelines and that's why you get a massive IO win because youve Scale based on the number of other pipelines that are reading from your data tables and so that's where like that's why IO can be so massive as like a win but obviously like if you're in the case where you're at the bottom of the um like data engineering tree where like your pipeline is producing a data set that is like visualized and in a dashboard and it's not master data but it's like more of that that that final like metric aggregation layer then um IO is is not going to be your biggest cost it's going to be compute probably it's going to be or it's going to be close between compute and storage probably compute probably compute and then storage would be your uh highest cost because you don't have that multiplicative effect of all those other pipelines reading from your pipeline so Cloud bills it's freaking there's a lot more we're going to talk about here with Cloud bills because I think this is a big area where you can have a big win both in terms of efficiency and in terms of Maintenance okay so let's talk about why too much IO can happen uh okay so obviously the first one is duplicative data models where you have uh yeah yeah I think this is one one thing that like a lot of our customers really need to be get quite concerned about just in general like just making sure that they are keeping track of what they're spending on because it's very easy for them to just overlog things and um paper services that they they don't need and a lot of the time we working with them to be like okay well these are what the services do the these you probably need to keep these ones up and running um but uh yeah it can definitely add up and a like using thing like services like a y open AIS is quite can be quite compute heavy as well which um make a lot can cost a lot of money uh ETL pipelines can be really expensive as well like when I was at airb there was when I first started there there was seven different definitions for availability like is available there was seven different ways that people Define that and uh and it's like why like why are we doing that like and I mean it's like that pain is actually that pain is not just in IO cost right that pain is also in communication overhead where it's like I say available you say available but we mean two different things and so like you also like in some ways that's even the bigger cost is on the communication overhead because employee time is just so expensive so like that's uh but like IO cost as well because it's like why do we have five different tables for this that where when we should have one and then those pipelines write every day and they are generating these tables every day and uh so that duplicative data models not enough robust data modeling big place where you eat an IO you have inefficient pipelines so imagine if you're doing like the monthly active user Pipeline and what do is you just read in the last 30 days of fact data and you do it that way and you make Zach sad because like I taught you better than that and like I taught you to use cumulative table design and because you don't need to scan 30 days of data to process this every day you can scan one day of data and then the the historical and then one day of data to calculate monthly active users my that's another place because in those cases if you're scanning 30 days of data every day that's a lot of IO right you're reading in 30 partitions every day when you could be reading in one another big place where you can eat a ton of IO cost and I'm always so painful so painful ow um um you also have uh excessive back fills where uh maybe you are trying to backfill a data set and like you're kind of hasty about it and you didn't uh validate all of your pipeline code yet and you didn't like really thoroughly validate it this is where um airbnbs might is programmed like they try to avoid these IO costs by they say first backfill one month of data and then validate that and then if that looks good that one month of data looks good then backfill the whole history of the data set because then you don't pay these IO costs over and over and over again if there's a bug because that's happened to me before and I've been there I've made this mistake myself many times like probably three at least three or four times in my career where like I backf seven years of data to be further there are genuinely some cases where like they're paying for like where I've seen customers paying for service what they just no longer using and they can save thousands just by turning it off uh so it's not always the case of optimizing you need to optimize until there's nothing but like there's definitely ways to make savings and then the analyst come back comes back to me and like these numbers don't add up and then I'm like wow I just gave I just gave Jeff Bezos like $5,000 I'm sorry Jeff or like you're you're welcome Jeff and I'm sorry uh Brian chesky or um or re Reed Hastings or Mark Zuckerberg I guess Mark Zuckerberg is he owns his own infa so like it's not it's different there but at at Netflix and Airbnb they both like give Jeff basos money so anyways uh back fills it's another uh way that you want to be careful make sure to follow backfill best practices and to be very confident that uh the data that you're going to backfill is going to be correct so that you don't just do it all over again because because backs are very expensive because it's like it's like running all of production for s years like that's like a lot if you're depending on how much history you're trying to back up uh then you have not sampling this the case where like you feel like you have to use the entire data set when you don't actually have to use all the entire data set you can do it without all of it uh that's like another kind of common problem I've seen uh also not subpartitioning correctly so subpartitions can be great because especially if your data table has another low cardinality column where you can that like you can split the data up in a more uh a cleaner way we're going to talk about that I have another slide here because predicate push down can be amazing in that case because if you have a sub partition what it allows you to do is it allows you to avoid reading in a big chunk of data that you don't need to read in and it because it it just ignores that folder because it gives you another layer of folders and it says oh our query doesn't want that folder because it's filtering it out and we don't even have to read in the data we just ignore it and so that's where sub partitioning can be very very powerful in uh avoiding large Cloud bills there is some trade-offs there and like I think that there are like there there are definitely cases where I've seen some partitions used incorrectly as well but that's generally speaking this is how I would imagine things would work with uh large Cloud bills those are going to be your big ways that um uh big symptoms or you know big causes of large Cloud bills that you can probably fix let's talk a little bit about why sub partitions work so imagine you have a table here we're call the table notifications and then this table has three partition or it has a sub partition on channel so it has a partition on date and a partition on channel and you'll see okay we have three um folders here we have a date we have one for January 1st January 1 January 1 for email SMS and push and one of the things you'll see is we have a query down here select star for notifications where date is January 1st and channel equals SMS so it you'll see when it when this query runs in spark it will skip this folder and it will not read in this data set at all so you don't pay the io cost where like if this wasn't subp partitioned right and say we were only uh partitioned on date then what would happen is we would read in all three of these data sets and then throw all of them away that didn't match SMS and then that would be extra IO cost that we wouldn't want to pay this is a great way to avoid that IO cost by like just immediately filtering it out because we know that none of the data in this um none of the data in this folder is going to be valid and so that is definitely one of the powerful things that you can do with sub partitioning especially if you have a sub partition that is kind of low cardinality um like I generally think of like if you have a sub partition it should be uh like it's similar to enom remember how we were talking about enums before where enums are like it should be like like 30 or less have like if it's like a we have the number of unique values is like 30 or less and usually it's like five or less but there are some edges where there's a little bit more but generally speaking it should be like 30 or less values this is where like country is always the one that's like some people are like yeah we should sub partition on country and it's like no dude don't do it like country is going to be annoying then like then you because yeah it's you typically well the the typical observation is like the way that companies make money is they either uh make money which is you know selling things and getting things sold or they reduce costs and reduce costs is fixed so there's only so much cost that they can reduce uh but the how much they can make is un Limitless so uh but but it's always good to have some people who are on both sides of the spectrum like of of of the coin because if people only care about making money then they aren't going to be worried about how much it costs to make that money so you kind of need someone who cares about the cost of what it costs to make sure that you you got that balance to actually make a proper profit if you do country then you're going to have to have like 200 tasks and that's super annoying so um you want it to be more of a low cardinality field that you and and one that people use in their filters a lot right because one of the things that was really powerful about this um subpartition in notifications is um one of these notifications types is a lot bigger than the others right push is two orders of magnitude bigger than SMS so it's like if you wanted if you didn't sub partition and you wanted to run a query that looked at SMS you would be like you would be reading in all the data and then throwing 99% of it away and paying that IO cost because you read it in you you read it off of S3 and just threw it away and just wasted it right and that's where subpartitioning can be very powerful in uh giving you more of an IO efficiency gain that I highly recommend looking into on especially if you have any big fact data that's where you're going to see some really big gains here so let's talk a little bit about um how these things are connected actually because IO compute and storage are not uh independent where like if you have bigger cables that are stored in bigger places and you read in more data like you're going to have more IO and so storage and IO are obviously connected and compute is also connect connected to these two right so um like what I was saying before large IO and compute are connected a lot because if you're scanning too much data you're going to be reading a lot more data and then you're going to be running a lot more uh that's going to tie up your spark executors for a longer period of time because that IO time is just like expensive so you want to make sure that you are not doing that uh sampling another great option here besides cumula TBL sampling predicate push down all that stuff um also make sure that you're like in your udfs you don't have any um N squared algorithms in that case that's where you have like Loops inside of Loops you have nested Loops in your algorithms you want to like make sure to kind of avoid those so there are some small edge cases where that's the only way to solve the problem but like n 99 times out of 100 that I've seen a nested luk in production it's it's Tech de it's not like oh yeah that guy just had the the best option he knew exactly what he was doing and he like he thought through everything now he was just trying to solve the problem the quickest way he thought of so um IO and storage are correlated um can confirm I've seen this happen before as well because if you're not leveraging par the file format the best then you're going to get a lot more IO costs because uh your storage tables are not compressed enough and if you can compress your data tables with par uh then your IO is less because when you read in the data it's compressed and then it only becomes uncompressed when you are already in the you're in the executor and you're already on the machine so then you don't have to worry about uh um you don't have to worry about the io cost at that point because the io is already done and because it's it's compressed already and so and then obviously the other one is duplicative data models just like what I said earlier where it's like if you have seven different definitions for the same thing you're going to get a lot of a lot of extra IO a lot of extra storage a lot of extras a lot of so that's that's why like data modeling is so important right and so so critical okay now this is uh this is one of the things that I find a little bit more near and dear to my heart because I think this is probably the most impactful work that you can do as a data engineer and it makes your job easier and it makes things more efficient and the maintenance is better it's like you win in every single way and there's no way that you lose that's the part that is so crazy about solving this problem here and like I so if you can solve these problems this is where you're GNA you're going to really find a lot of impact as a data engineer and this is like solving these problems is also like where I got really good performance reviews at Airbnb and all all sorts of stuff like that as well and so let's let's dig a little bit into this so it's very common especially as an organization gets bigger and bigger and they have more and more needs for data that uh they don't have enough data Engineers or they don't have enough data infrastructure and like what ends up happening is like different aspects of the company are like well I need this data set and I just need it as quickly as I can get it right and they don't really care as much about the quality and they don't really care as much about like if other people have already created it they might search real quick to see and then if it's there great if not they'll go make it themselves and then they'll keep doing that um so this work is complicated because of the fact that one when people do these multiple sources and they have multiple pipelines that are producing the same thing um they might have different variations of the same definition so usually that means that you have to convince somebody that their definition is wrong because um or maybe not wrong but at least kind of not correct and that is going to be can be tricky sometimes because some sometimes even people who are not data Engineers are kind of married to the data that they created and they're like no I this is the most most correct way to do it and so you want to get all these stakeholders in a room so like for example for me when I was like trying to solve this like many many many different many many many different definitions of availability at Airbnb like I had to get so many people in rooms and just talk it out and see like how we could solve this problem and going forward and like both like and the thing that was crazy about the way that I solved that problem was that we didn't end up picking any of the ones that already existed we created a new definition and then everyone agreed on that definition because they were like yeah that's the most correct definition so sometimes that's the other thing about these multiple sources of Truth is that they can all be wrong or they can all have problems as well and that like there's actually another path forward that might be uh the most correct or the most efficient or the best and so just because there's multiple sources of Truth doesn't necessarily mean that one of them is you know quote unquote the truth that that there's actually uh um potentially room for improvements on all of it and so a big thing to to look at here is you want to document all the sources of truth that you can find this is a big thing I remember I had this spreadsheet at Airbnb that had like it was like it had like 30 or 40 tables in it and like is it I love R cubes it's it's a good um it's a good distraction when I'm finding something uh quite um what the word I'm finding it difficult to to to focus on something it helps me like focus on it more which is I know feels a bit opposite but but it it does really really helps I was like if we can just consolidate all of these tables can go away and we don't need any of them and we can go from 40 tables to four and it would be better it' be a lot better and that was the vision I sold my manager on I'm like it's going to be so much better and you need to document these things It's Tricky though because of the fact that like one people can name a table whatever they want so it can be tricky to even necessarily find all the sources of truth that's why like generally speaking you don't find all the sources of Truth via code search or via like grap or however technical way you want to do it that can be a good way to get a good like fundamental start but like you really do want to talk with all the relevant business people all the relevant people who like in all the areas of the business that might be using this data because then uh you'll you could uncover some really funky table names things that you didn't even consider someone might have name their table qqxx l l lore W and they're like yep that's availability and it's like okay bro okay it's availability I guess right and um anyways uh you can't just rely on like searching the code base to find these tables you need to talk conversations important and these conversations are also important anyways because it can help you understand like why they're using this data and also understanding maybe the pain that they're having with this data or the the the lack of completeness or the difficulty or like all sorts of other things that you also want to pick up right where like if you're part of the combined track uh yesterday we were talking a lot about being a product manager and this is a very relevant place to be here where like if you're building a pipeline you want to be a data product manager where like you want to understand end to end how to Delight your customers where a big part of that is completeness another part is quality another part C is just refresh freshness quality completeness ease of use all of those things are very important and then also if you take a pipeline off of someone's plate they'll love you forever because then they're like wow I don't have to manage this Beast anymore and you will just manage it all for me like thank you so like that's why you also get a lot of claps and a lot of um kudos for doing this as well because like in in in my case at Airbnb there was like okay there was seven different pipelines at least of you know generating different availability definitions and then like then we turned it into one that we owned and then it was like okay all those other pipelines that people were using we don't need anymore and so that was another way to get a lot of Kudos lot respect right is you're deleting work for people and deleting maintenance for other people it can be tricky because sometimes it's like you're deleting maintenance for them but you're putting more maintenance on yourself so you want to like have a good balance of all that stuff obviously you don't want to try to be a superhero um and then after you have all the needs and you have taken in all the pain and you've documented all of the discrepancies and all of the different sources of truth that's when you want to build a new spec and you want to build out the spec of the new pipeline that you want to build that's going to consolidate all of these things and be the New Path forward that then you can talk to all the stakeholders about and like this is what we're going to go to we're going to migrate to this it's going to save you all this pain can you agree to it and you want them to agree before you build or before you start writing the code because they might not agree to it and like if they don't agree to it then uh the problem is is then like if they don't migrate then a lot of your work is for nothing because then they're still going to be using their own other definition and then like all of that hard work of consolidating definitions is not like is just dead so it's all about getting that stakeholder bu in making sure that everyone's on the same page most of the time it's easy sometimes it's a little bit harder but most of the time people are like grateful that you're doing it so those are the three steps like and a lot of that's a conversational thing not very not very technical actually it's very um human very empathetic very product manager right remember I was saying you know talk with all of the stakeholders code search for similar names like you know you might want to gret for availability or something like that and then uh you can also like potentially if your company's really ahead of the game it might have lineage so then you can like go up to the source data because a lot of times even if you have different definitions of something they all read from the same Source or you mad I can't I can't like sit there and have an unsolved Rubik's Cube on my desk are you mad you mad that would be like a crime I cannot think about that juggler that saw four Rubik cues while juggling real quick since I saw it Oh my God that's say no I could not do that at least some of the same sources so then you can find like the most raw log data or the most raw like database snapshots and those tables are going to like the the downstream of those tables are going to be the the definition tables that you're looking for and that can be another way to find that stuff not very many companies have lineage though lineage is like kind of a new thing I think that that's going to be in the future I think that's like going to be a good thing that's one of the things that uh you know have you heard about Microsoft fabric I've heard that fabric gives you that like out of the box so if you just like use fabric then you get lineage for everything and like that's cool I like lineage I think that like being able to see where data comes from is very powerful and it allows you to do a lot of this good work as you kind of go forward with stuff so definitely do that um okay another thing that you want to do when you're like consolidating all these sources of Truth is understanding like how it got here because there's more problems here than just the fact that there's seven data tables like there there's other problems here that are also important to talk about and also important to bring up um for example one of the things that can happen in a lot of these cases is you can have organizational um problems where what actually happens why there's multiple sources of Truth is one team doesn't trust another team to deliver and so they just go and build it themselves and it's like why is that the solution right and it's like when like that's where trust is super important where you need to have trust between teams otherwise like you're gonna have this you're gonna have Tech de like this come up all the time you have an ownership problem as well like uh for example the team that should own this doesn't have the bandwidth to own it so another team's like okay fine we have a little bit of spare bandwidth so we're going to take it on and that could be another kind of problem but then they aren't the right team to own it because they actually don't have enough of the business domain to actually do a good job job so that's like more usually that's more like a staffing problem where they they should probably move one engineer to the other team so that then they can own that that data set which is very hard to do by the way um you have technical technical would be like okay uh the team that should own this that's deep man that's really deep any Rubik's Cube that's is already solved you just don't see it that is super deep um I think the thing that's the thing that's beautiful I guess if I it though is that there are so many different ways to solve it like in the way that it's meant to like the real challenge is being given a pattern and been asked to solve it for that pattern now I can't do that for many patterns because it would ruin my head but um but yeah it you could be theoretically you could apply the same algorithm no matter what as long as you knew the difference where the different things needed to be doesn't have the technical skills to own it and then one of the teams that we have does have the technical skills a lot of these are a combination of organizational and ownership and Technical right Technical and skills are the same way and obviously there's going to be a long tale of other reasons why we have duplicative data sets potentially coming up but the whole thing about this and why you need to have these conversations especially if you're like going to become a data leader is if you can solve the organizational problem if you can solve the trust problem and the ownership problem then you stop the bleeding you stop this problem from proliferating and then you can get people to trust each other more and then you can get more Consolidated data sets that way and then less maintenance more efficient awesome right it's really good and then like another thing that's super important is like working with these stakeholders uh to understand what the ownership model should look like and also like how changes should be incorporated like if a model if a model does need up later on like how who's going to drive that and who's going to build that out right and really hammering that down so that people uh in these other teams can trust that this data set will not just serve them after it's migrated but that it will serve them in the future as well and that could be another great way to build trust and to build uh just just just to build a lot of like uh Rapport and to make people really like you as well because they're like they're because you're taking something off of their plate and also guaranteeing to them that it's going to be it will be managed in the future as well that's awesome that's like you're taking work off you're taking work from them immediately and future work so like like that's a that's a that's a lot of love you know it's a lot of love so remember to spread the love around I love specs peline specs are so great right and that's what I was saying earlier got to build a spec get all the needs get everyone to sign off and then because once they sign off and you have like a signature from them or you have like a like they said this was good then that is like when when it comes time for them to actually move and migrate their Downstream pipelines like you can kind of bully them into doing it because you're like yo D you said you were going to do it and because migrations are so painful they're always so painful and uh and like having a document like this could be very helpful in getting people to actually do it let's talk about a little bit about the different models for fixing Tech debt I think there's a real common occurring theme in all this though and for me it seems that really the recurring theme from this is to make that impact is to do the things that you wouldn't necessarily find fun like you know you not you know doing the documentation the specs and the talking with relevant St those aren't necessarily the most fun parts of the job defining standards aren't isn't necessarily the most fun part of the job however they're going to be the most impactful things in terms of having your pipeline be used by others of like kind of the team ways of fixing Tech de that I've seen these are essentially the three that I've seen where you have a the first one is called like fix as you go it's also called like boy scouting it's also called like a bunch of things like that but it's like mostly like when you're shipping new features fix the tech as you go and it's it's it's an interesting model we're going to talk about the pros and cons here in a second uh then you have like allocate a portion of time each quarter so a lot of times this is what airb did was the second one uh it's called the tech Excellence week which was the last week of the quarter the last week of every quarter we uh just did not work on new features we only worked on cleaning up Tech debt and amazing by the way I love it loved it so much and then uh the last one this is the way that uh it worked at Netflix was uh instead you have the on person focus on Tech because they get slapped in the face every day with the tech because of they have to fix the on call problems and to deal with the maintenance themselves so then we're like okay on call person just if you're dealing with the maintenance already and you're unblocking things why don't you not just unblock but also fix things so you get kind of both in that way but these these three methods have their kind of pros and cons right obviously fix as you go uh the biggest Pro here is uh like it's not very structured and like you can there isn't much incremental burden like you're not taking away from very much else um I think the con here with this model is that like like it sounds too good to be true a little bit where it's like oh yeah as you're coding just fix the tech debt it's almost like as you're shipping features fix the tech de right it's like almost like as you're flying the plane fix the plane and it's like I don't know about that fam I don't know if that's like a an actual viable model or not if it is cool if not like I don't I haven't ever seen it work in practice all right I I mean that's what Facebook was all about and Facebook freaking was a mess in terms of tech that Facebook was by far the biggest of the messes so um then you have the allocate dedicated Time Each border right you actually fix things in big bursts it's great um one of the problems with this though I found is that like people essentially uh if you do have that dedicated time at the end of the quarter you don't have the as you go fixes and a lot of times you get like you get this like Tech de line and then it's like cliff and then build up and Cliff right and it's like a crazy and like so at the end of the like the the second to the last week of the quarter there's a lot more Tech de in the code base right and then and you're not like it's almost like it's almost like saying like oh I'm Gonna Save up all my teeth brushing and I'm just G to brush one time for 90 minutes at the end of the quarter and like I mean I don't know that I don't know if that's how it actually works but uh that's um that's generally speaking that's how I've seen it work uh the other minus here is then uh people during that week they don't have time to help stakeholders or to ship other features or other things like it comes it comes at a pretty heavy cost for that week I mean you spend a month a year uh working just on Tech Deb which is a significant amount of time that you could be using to spend other things kind of like the opportunity cost um having the on call person uh due Tech Deb uh the cool thing thing about that is that they are very aware of what the most urgent Tech debt things are because those things are slapping them in the face because they're like wow this is failing this is failing everything's on fire and then they have to get their fire extinguisher out and then they like try to fix stuff right um I don't know like one of the things I've noticed with this model was that like one uh some people don't actually do it uh I think that that's one of the things I like about the dedicated week as opposed to doing onf person do Tech de is the dedicated week is like everybody is doing Tech dead that week so you can kind of like there's this expectation that you all ship something that you all clean stuff up and that like you're going to hold each other accountable uh I found with the on when you have when you say the on call person needs to detect that that they don't actually do it that like uh I would say only like half the people actually do it and that was actually something that frustrated me a lot when I worked at Netflix because I was like Yo dude like if this is our model like why aren't we cleaning stuff up why aren't you actually dedicating the time to that and like a lot of times it would be they would want to spend that time working on new features or working on other stuff right and working on the things that are going to like get them promoted because a lot of times Tech that stuff is uh not as visible and so uh they get gets deprioritized and that's where that's why I really do like the the dedicated time each quar cuz then it's like well it's not as visible but we're all going to work on it together at the same time and then it's like because it's like it's kind of a team effort in that way like it takes a village to um you know tackle Tech de and so those are the three models obviously I biased y'all into saying which one I like the most but I also think the one that I like the most is the heaviest it's the one that takes up the most time it's the one that uh the way I think about is it's the one that really takes it seriously though it doesn't just treat it like a secondary priority or like something that I'll get around to it if I can right it actually uh treats it as like we're going to block out time for this every every quarter so uh definitely try out all three tell me how it goes like if y'all can figure out how to get the fix as you go to work I think so in a lot of teams that I work in um we typically have planned planned Sprints not like fully planned like you know it they're flexible but for me like my view is if if I've got a few days left and and they don't want me to bring anything like any any new features in um to get started on uh that then I tackle my I tackled Tech then um yeah I'd love it I think that like I want to hear uh the success stories there because like if that actually works I think that I would like I I think that that would that's why I would want to do it but I just don't think that it's it's realistic okay let's talk about the data migration models and then we will be almost to uh the Run books part of this presentation so essentially there are two ways to go when you're migrating things and I have a good story here because Airbnb changed their mind on this which was so crazy so if you're building a new data model so you know in that example I was talking about earlier where we like built a spec and we got all the stakeholders sign off and we build a pipeline and we back build a pipeline and we have a pipeline running in production and then there is still that time between when you have that pipeline running in production and when other people migrate and they move they depend on your data instead of the old data there's like a there's that time and there's like these parallel pipelines that both need to run and one of the things about that is it's kind of expensive because then you're essentially paying 2x uh the cost of that pipeline for the duration of the migration and that's like painful and one of the things I noticed is that like when that happened I uh like so initially the migrations I was working on at um Airbnb like when we made a new pipeline it would take like six months for people to migrate and then we just have two pipelines for six months and then like sometimes it was like is this even better like we're just adding another Pipeline and we're holding on to both for six months and this was actually a very common problem at Airbnb in21 where they were like uh and eventually leadership came out and they said like y'all are being too cautious like if things break things break and people need to migrate because the problem is like everyone is being too cautious about breaking other people's pipelines or making other people's data delayed and uh they didn't drop the tables or stop the Legacy or the deprecated pipelines soon enough and so what ended up happening later on they were essentially like you got you give them a month if they don't migrate in a month you start breaking stuff that's essentially what they change their mind right so that like so that we don't have this like crazy long period of time where like the migration takes forever and people are just deprioritizing moving the tables and back filling and all that stuff because it's not fun it's not fun migrating data is not fun it's literally the least fun part of data engineering all right and it's like the most boring least one part of dat engineering so like I get why people don't do it and so that's why like uh they only want to do it if they have to and the way that you force them to do it is you delete the old Pipeline and you make it so that their pipeline just doesn't run anymore because now their pipeline can't run because the Upstream data doesn't exist and the only way that they can uh get their pipeline to run again is by migrating and that's why there's this new the new one is called the bull in a china shop approach where it's like okay once the new pipeline is up and running like might as well migrate things so like the way I did it when I was looking at like pricing and availability stuff was I was like okay we're gonna move uh any of the ml stuff any of the expensive things that like if they broke and were delayed then we're gonna migrate those and then once those are migrated everybody else can just break and then they can migrate as soon as they can right and then they can just get their stuff to migrate because it doesn't matter that much right because if it's play by a week it still doesn't matter that much CU their data set isn't that high impact anyway and it's actually more impactful uh on the tech debt buildup and like on my own team's well-being to have two pipelines running in parallel for n number of months so this is something that like I found very interesting and I was very grateful that Airbnb changed their policy on this because fre that first one was so painful where it was like essentially how it worked was like it was like three months where they run in parallel and then after three months you rename you uh you keep them both running in parallel but the the deprecated table you rename to like table underscore do not use and then have it run for another couple months and then uh and then drop it off at that point and I was always like dude like these zombie tables just need to freaking die man like why aren't these dying right and so definitely uh they both have their benefits and risks though because um the cautious approach the thing about it is though is that's a very um it's a very accommodating way of doing data migrations because if you just Break Stuff the thing is is like the other team is going to be like hey you just put work on my plate like why you doing that why why you being a dick why why you put work on my plate you don't want yeah you don't want that right so um and so but like they learned that that's actually the better way to go that like if because it's usually not that much work to migrate so let's talk a little bit about on call proper on call responsibilities uh so there's a couple things here that I want to talk about uh so one is around uh set up proper expectations with your stakeholders I think this is the most important part of on call because uh if you can get this right then your en Calla will usually be a breeze um because at least like when I was working at Airbnb originally the um uh the the expectation was that any on call Bug was going to be troubleshooted in four hours and I did that for six months and I was like I'm not doing this like I'm not four hours is stupid because then it's like if it fails at midnight I have to troubleshoot by 400 a.m. like no like I'm not doing this and I changed it from four hours and I was like you know what we're doing we're doing 24 hours that's what we're doing and like they there was initially push back because they were like why why are you making it worse why like why can't you do that I'm like because I'm like this four hours freaking sucks like and like I don't want to have to wake up in the middle of the night and like it's bad for my mental health and bad for my wellbeing and it makes me hate my job and like and the thing but also I told them that but also um another angle from it is that like it makes no impact on the downstream there's actually no impact really on the downstream unless the data is more than a data late so uh like that's I think good enough and uh that's where you can have some really good conversations with your stakeholders and the data engineer before you well how how how sir thanks out go back okay no worries um um yeah how do you live in a like different world do you have very different data engineering problems to him might have been crazy and done things in a way that like wasn't sustainable for you and you might want to reset those expectations and don't think like the expectations the on call expectations going into the job are are what they have to be forever like you can it is within your power to make changes to that um the other thing document every failure in bug uh you'll usually get an email from airflow or an email from your drop orchestrator if something breaks uh make sure to document it and put it in some sort of Google doc so that you can keep track of all the failures so that you can find the problem children so that like your on call can get smoother and smoother and smoother and obviously you have like on call handoff which is where uh that's where usually on call lasts a week and then you'll pass it to another person and then that person will and then you have to give them all the context of like anything that is currently broken or things that broke over that week and then that's us like a 20 30 minute meeting to sync up with people to get them to be ready for their on rotation okay run books Let's talk about run books a little bit uh and we're going to we'll have a little bit of time to maybe create a little bit of a run book so uh complex pipelines need run books not every pipeline needs run books uh you only need run books if like there's pipelines that have like a lot of inputs or they have outputs that are used by a lot of teams or they have a lot of complicated logic or a lot of data quality checks or like you know things like that those are going to be the big things that you need in the Run book and I think one of the things that's important here to differentiate is what's the difference between a run book and a spec because they are similar uh and like some some people actually say that they're the same and the Run book it should be in the spec and that like the Run book is just like an evolving part of the spec uh so that's a big thing to remember um so the big things that you want to put in the Run book primary and secondary owners this is whether this goes in the Run book or the spec is like here or there usually if that's in the spec it can be in the Run book too and that's going to be like essentially the primary owner is like who you tap if if you're on call and a pipeline breaks and you don't know how to troubleshoot it the primary owners who you tap and if they're on vacation you tap the secondary owner and if they're on vacation like you freak out uh and like if a lot of times there isn't a secondary owner and that could be a problem as well uh because I I found that big Tech doesn't do a good job at uh allocating to Engineers for every pipeline but uh that could be a thing um another very important part of this is listing all the Upstream owners because one of the most common things that happens in data pipelines is the Upstream data quality checks fail and if you have Upstream data quality checks fail then you need to talk with those teams and be like yo your data sucks fix it and uh you want this to be teams not individuals the main reason for that is that uh Team ownership fluctuates less than individual ownership because um reords happen less often than people leaving the company coming in uh people entering and leaving the company so it's better to actually have uh the contact Point via team then to have the contact point being individual because then at least like that because that person might leave the company and uh then you're screwed because you have no idea who like they're going to go to so uh that's a big thing that I would imagine and like but even still you can have reords that happen and uh that team identifier might also be kind of bogus so you want to be careful there um another big thing here is common issues so this is usually part of like the common issues is something that that gets filled out over time that usually the on call person should be taking some of like if they're if they're copying and looking at all those stack traces and failures that are happening they should describe what happens and then the common way to troubleshoot it right the common process to troubleshoot it assuming that they can't fix it more long term right they can't like it's like just kind of a fundamental nature of the data as opposed to um uh something that is like a bug right where there are pipelines that are like that like where you have like just like why do you not have vacation especially like I know like scraping Lin if you're like scraping the web or whatever you're going to have a lot of common issues that like just happen because you don't have control of the source data um then you have critical Downstream owners these are the people that you need to talk to these people are going to be the people who like especially you don't need to like document all your Downstream owners like you just need to document the ones that matter the most right for me it was like Smart Pricing was the big one that like the ml model Downstream where it's like I knew if the pricing data was delayed I had to talk with Smart Pricing quickly just so that they were aware that like the pipeline was going to uh be kicking back up and I was troubleshooting it and figuring out what was going on last but not least is slas and agreements so slas here's service level agreement which is kind of duplicate of your SL and agreements to both agreements and uh in this case this is like usually this is a number of hours sometimes a number of days number of hours or days uh after midnight for that day when the data is expected to arrive and this is the agreement essentially between you and your stakeholders that says okay the data is not late until it's been this many hours after midnight and that's going to be uh how you can kind of prevent a lot of your stakeholder questions from getting out of hand is by uh because they're not going to be like hey why is it late and then you're like it's actually not late yet it's going to be late in like 5 hours so don't quit pinging me right now so that's a thing to remember as you're kind of like going through this stuff uh so these are the kind of the critical aspects of a run book and if you can have all these things in one dock then you're going to be in a good spot uh there is stuff that's a pain right um but here's an example I think that I think will kind of give you a better kind of view of what I mean by how run books can be helpful so you have over here on the left you have uh um kind of your Upstream owners right so you have like owned by Joe mama a monetization team he owns coupons and credits and then Henry on the finance team owns revenue and then Karen on the customer service team owns the customer service data then you have your pipeline and then these are your output data sets and then these are your Downstream consumers that you want to talk to if this stuff breaks right and some of the times like depending on how mature your data infrastructure is some of the stuff can be completely automated so that these people will actually be aware of a delay or aware of a breakage uh without you having to to contact them which is great but like if it's a very long delay they're going to ping you and be like why is the data late like why have you troubleshooted this right and so you want to be able to have a good conversation and a good communication with that person as well so that you can have a kind of a a picture in your mind of okay this is the person that uh I need to talk to and generally speaking when you're building these pipelines this is just another part of this process that I find to be very valuable which is not quite as technical but is a a good part of this process as well is you should have a regularly uh recurring meeting with everybody on both sides of this so for example in this case I would probably have three uh maybe quarterly or monthly or quarterly one-on ones with Joe mama Henry and Karen and then also with experimentation and pricing teams customer service team and efficiency team I would have uh at least a at least a quarterly if not a monthly one-on-one with each of those teams so that uh we can just be all on the same page and then also just to understand like where they're trying to go and if we can improve some of these data sets to make them better so that like you get like it's great because then in those cases you just get a way better connection with all of your stakeholders and you're just more integrated in the business overall and you get a nice benefit from this of like hey we are um uh the the your stakeholders will be nicer to you when there's problems because like you actually showed that you care about investing in the relationship over the long run so it makes your life easier because then you're like oh like um because I I ran into this problem a long time especially like early in my career when I was on call was that like I would I would have stakeholders Downstream who like I were just like unnamed right or like I just didn't even have a face to put on this stakeholder because there was just like a lot of stakeholders or a lot of people right and then there's like I don't even know I'm I'm I'm making Unknown People angry by delaying their data sets and uh and so like and I was always that kind of stressed me out and so I found that like you definitely want to do relationship building with all of your upstream and all of your Downstream consumers as a data engineer because then like you're going to just catch things so much better and it solves the other problems as well it solves those uh duplicative data modeling problems it solves like so much of the other kind of pieces of the puzzle so we go create a new Doc here and then uh call this uh run book stickers would be nice to me um me or just in general when you build a relationship for exactly Inc growth pipeline obviously I'm a startup so like some I don't really have stakeholders but we're going to pretend that I do have stakeholders so uh so in this case uh what we want to say here is uh usually want like a title right we'll call this on call run book for exactly Inc growth pipeline okay so we have like our Upstream data sets and this is going to be like uh events we say like website events and then we have uh user exports then we have Downstream um consumers we have experimentation platform and we have uh dashboards say both like that right uh user database exports so these are going to be our two kind of uh different ways of doing things right and we this is our we remember since I was listing my upstream and downstream data sets right and then in here we have like common anomalies right um or like uh sometimes a referer is null too much uh this is fixed Downstream but we are alerted about it because it messes with the metrics right something like that because you can also have like data quality checks that are non-blocking right but they alert you because like they want to let you know that like you might need to talk with the dashboard users or the experimentation platform and then you have like your user database uh you know export might fail um to be extracted on a given day when this happens uh export as soon as possible and just use tomorrow's or no use yesterday's that's actually is when this happens use just use yesterday's export for today something like that right depending on like how reliable your infrastructure is obviously this isn't item potent and I hate it but like that might be what your run book is as a company right and so this is the idea right so you have like your common issues like you probably want to call this like common issues and this is like bolded and like big and then like obviously you have a primary owner this going to be Zach secondary secondary owner is Lulu right and then we have uh well there was there was some more pieces of this right we have the um run books right so uh primary Upstream owners common issues critical dat then slas and agreements right so uh let's put that in here so we can say um slas bigger then uh in this case uh this is data should land um 4 hours after a UTC midnight or something like that right so obviously these run books are probably like Zack this is like the most ugly run book you I've ever seen you write in your entire career and you're kind of right about that but uh the idea here right is now if someone goes to this Pipeline and then they were like like I see this like refer anomaly and then it's like boom done right but then it's like okay and then you want to question like okay if that's the case maybe we need to remove that check and just and make it so it's like a higher um signal to noise ratio where like the actual alerts are that way but but it's kind of hard to do that over the long run like of just actually uh like fixing all your data quality checks and like some of them are going to be noisy sometimes but that's kind of the idea right and this is obviously the I I expect a lot more out of y'all because you're going to like hopefully create a kind of a pipeline spec that is um if you're in the combine group you're lucky because you already created a spec that has a pipeline but like if not if you're like in the infrastructure group then you need to also create just like a pipeline that describes things with inputs and outputs and then uh it it can also describe potential common issues and slas so that you this this is going to be your homework for uh this week and it's done in groups though so you don't have to like it's it's a lot I'm actually asking for quite a bit especially if you're uh if you didn't do the uh analytics homework in week three then uh this is going to be a significant amount of work congrats on getting to the end of the day two lecture if you like this Channel and like this boot camp make sure to like comment and subscribe and share this content with your friends I'm so happy that you're taking this time to invest in your knowledge and getting better at data see you at the next one how relevant is this if we Define boring always to the other boring I don't know what that means oh look I've watched everything now which is good just need to get my assignments done so I'm just going to have a look at what my assignments left so I I found that particular one a little bit dull but I didn't find uh I didn't find the majority of them though it was just this particular one but to be fair like there are parts of the job that are just not as enjoyable as other parts of the job so and but they're the most impactful stuff so uh yeah imagine you're in a group of dat Engineers you will be in charge of creating things you are in charge of managing these five P plans that cover the following business areas profit unit level profit needed for experiments aggregate profit reported to investors growth aggregate growth reported to investors daily growth needed for experement engagement agregate engagement reported to investors you are in charge of figuring out the following things um Andre oh thank you I'm glad you found them useful who is the prim second of these pipelines what is an on call schedule that is fair think about holidays to okay that's a AIA okay e oh really I'm glad that the home white ones have been helpful um I've had a few people say that the homework ones were helpful for them so I'm glad that they like that people have managed to get their homework done without from them um down and submit it imagine you've got a you be in charge of in charge of managing these pipelines that business areas so let's just go there let's put that there let's make this a little bit larger cuz someone asked if I could make it larg last time let's get that there for me I don't know if this is like thingy but like do I just make this up I'm just going to like see what chat seases yeah so it is you literally just what you just make it up so basically um we make it up right I'm going to call my um let's copy this let's create team what what should we call Dat engineer one I'm going to call data engineer one Bob no Alice Bob charie what should we call Dat engineer for Dary let's call him Dary I'm going to say Bob and then I'm going to say Dary dary's got it lucky she's not um secondary she's not a primary owner of any of these Pipelines we're going to we're going to say that to ensure fairness and account for whole days we're going to rotate our on call the weekly schedule yep chat GT you got it right there each engineer will be on call for one week and the schedule will be adjusted to ensure that no one is on call during the prim holidays okay okay I think that's fine let's call it data engineering team let's see this for I'm not very good with like imaginative play like this like is just okay right let's see what happens if I submit that for e so I've submitted it like that and I have got a B what's the what's the feedback right yeah I'm super lazy so I'm just going to um add this I doing documentation it's the worst thing in the world but like chat like if anything if chat is GNA anything it's the documentation side of stuff where am I just got rid of my body okay dy I wanted Dy to be my just going to do ites quality isues uh cool me just put that in another zip okay yeah cool so I mostly just use chat gbt for this just because for stuff like this where I'm just making crap up I don't see the point in spending a l of time on it um but basically let's view this in M down so it looks nicer what we've said is we're going to have a datto engineering team oh no that looks better and then is that so we have a okay I know why because of this y so let's put this in its own thing let's do this as the engineer team I don't know why I'm editing it now I don't even it doesn't even matter anymore um okay and so we then have our D engineering team is Alice Bob Char and Dary we have two we have primary and secondary the pipelines so we've got pipelines primary owner is Alice and secondary owner is Bob uh because Alice has become a financial dat to expert and Bob is familiar with profit metrics whatever making like I said I'm really bad at making stuff up um primary owner Charlie secondary own Darcy primary on a bob second year and a Dary to ensure fairness and CP holidays weekly SCH blah blah blah cool um profit Pipeline on call procedures yeah so yeah you know just made some metrics up for this like I see this in a real scenario like completely get that this is really important when you're doing it like in a team yeah but for this you can just make up whatever you want really I got an A which is fabulous okay so I'm just going to go to my assignments my dashboard so I've completed all my assignments apparently which I don't understand because anyone who's doing it there is are we not meant to do this one as well is anyone is anyone else who's done the boot camp than the last one um e e okay I I I'll ask um someone who on the Cass about this but yeah uh I'll see if I need to do the other homework I I'll ask around and if I do I'll do another stream on that but yeah I need to figure that out really yeah thank you for those who have watched this and yeah I think if I either have finished the course now or I need to do that last homework we'll see I'll I'll let you know if if I finished it I'll I'll do a person LinkedIn if I need to do the last homework I'll do another stream but thank you for those who have stayed and watched uh throughout and yeah this has been a great journey and I've learned a lot so thank you for those who have watched and yeah um hopefully in the hopefully either we'll do something different maybe I can stream something different let let me know if I should do some other stuff other challenges other courses and yeah if if so it'll be fun to stream those if not uh thank you for joining me along the journey it's been fun bye everyone


 > [!info]
> - **0:13**: Tech debt signals: pipelines breaking, large cloud bills, multiple sources of truth, unclear/undocumented datasets.
> - **1:10**:  The only thing better than optimized is deprecated (delete unnecessary pipelines).
> - **5:35**: Question the value of inherited pipelines; is it worth being on call for?
> - **6:55**:  Options for fixing painful pipelines: migrate to new tech, better data modeling, bucketing, sampling.
> - **7:41**: Bucketing and sampling can significantly reduce pipeline complexity.
> - **10:47**: Consider streaming for reliability due to consistent memory footprint vs. batch processing.
> - **13:36**: Consult a data scientist about data shape before sampling to ensure a random and representative sample.
> - **16:07**: Bucketing: Avoid shuffle operations by pre-partitioning data; critical for hyperscale data.
> - **20:58**: Don't bucket tables under a terabyte.
> - **21:16**: Cloud bill costs: IO, compute, storage (IO usually biggest).
> - **22:39**: IO is expensive; be mindful of duplicative writes (e.g., write-audit-publish pattern).
> - **25:46**: Duplicative data models lead to communication overhead and increased IO costs.
> - **27:02**:  Backfill data cautiously; validate code before backfilling large datasets.
> - **28:41**:  Sub-partitioning can help avoid reading unnecessary data (predicate pushdown).
> - **34:28**: Solving multiple sources of truth brings high impact, improves efficiency and maintenance.
> - **35:30**:  Document all sources of truth, talk to business people to uncover all data sources.
> - **39:37**: Build a new spec for consolidated pipelines, get stakeholder buy-in before building.
> - **42:12**: Address organizational problems (trust, ownership) to prevent data duplication.
> - **45:57**:  Create a timeline for when old systems are switched off.
> - **55:31**: Set proper on-call expectations with stakeholders (e.g., response time).
> - **57:59**: Complex pipelines need runbooks (primary/secondary owners, upstream owners, common issues, downstream owners, SLAs).
> - **1:03:35**: Build relationships with upstream/downstream stakeholders.
> - **1:07:10**: Runbooks document: common issues and solutions, primary/secondary owners, SLAs