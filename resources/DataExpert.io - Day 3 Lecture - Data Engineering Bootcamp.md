---
title: "DataExpert.io - Day 3 Lecture - Data Engineering Bootcamp"
author:
  - "Jade Codes"
published: 2024-11-26
source: "https://www.youtube.com/watch?v=XSIg26KcQi4&t=1s"
image: "https://i.ytimg.com/vi/XSIg26KcQi4/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGC0gZihyMA8=&rs=AOn4CLBX00QeEhx8I7nK7p7l0IdmLl0siA"
created: 2025-03-23
tags:
  - "youtube"
  - "data_engineering"
  - "graph_databases"
  - "data_modeling"
summary: "Day 3 of a Data Engineering Bootcamp covers additive vs. non-additive dimensions, enums, flexible schemas, and graph data modeling for building scalable data pipelines."
---
# DataExpert.io - Day 3 Lecture - Data Engineering Bootcamp

![DataExpert.io - Day 3 Lecture - Data Engineering Bootcamp](https://www.youtube.com/embed/XSIg26KcQi4&t=1s)

> [!summary]- Description
> Thank you for joining me on my Data Engineering Bootcamp journey!
> 
> I'm so excited to have you here as we work through this incredible free bootcamp together. A huge shoutout to Zach for creating such an amazing resource!  
> 
> Before we dive in, let’s go over a few quick house rules:  
> 1️⃣ If you’re also following along with the bootcamp, make sure you check out the official site at:
> https://bootcamp.techcreator.io/ 
> 2️⃣ Don’t forget to watch Zach's videos directly too! He deserves the watch hours, and you deserve the credit for completing the bootcamp.  
> 
> This bootcamp is completely free, but I also want to let you know I’ll be joining Zach's paid bootcamp in January. 
> 
> If you're interested in leveling up your skills even further, you can use my link for 20% off: 
> https://www.dataexpert.io/jade
> 
> Thank you again for being here, let’s make the most of this bootcamp and learn some amazing skills together!

> [!note]- Transcript (Youtube)
> for I'm just sorry I'm just waiting um boot. data expert someone wants the is that the right one s someone ask me for it does any another the link for his boot camp just I'm just going to start just uh get my Bluetooth up this amazing is more relationship focused and less entity focused so if you're looking at how things are connected that is going to be where graph data modeling truly shines but it comes with a tradeoff where you don't really have as much of a schema around the property so the schema in most of the graph data modeling is very flexible it just has like a vertex and properties or an edge and properties the schemas are very very limsy and flexible and so I worked a lot with graph data modeling when I worked with Netflix we built graphs that had 70 80 different types of things in them so that we can understand how everything is connected and you might end up ultimately loading the stuff into like a graph database but in today's lecture we're going to be talking about just the data layer and how to build a data ostic graph data model and I hope you enjoy the lecture today and if you want to learn more about how to build graph data models in the cloud with hot Technologies like Iceberg and trino definitely check out the data expert Academy in the description below okay so today we're going to be talking about a couple things here we're going to be talking about uh additive versus non-additive Dimensions uh which is a perplexing little concept uh that I'm definitely going to help illustrate here then we also have have uh the power of enums uh enums and enumerations we we covered a little bit about enums in day one and two remember like scoring class right um I need to mute people I'm getting some Echo I think it was like fegar can you uh mute yourself uh anyways uh and then we're also going to be talking about when you should use flexible data types like in this case flexible data type is only counts for map map is the only one that's flexible struct is not flexible because you have to Define all the keys and all of the data types of everything in the struct and array is also array is kind of flexible because you can like add more things to it and but like usually array has to be like an array of string or an array of a specific type and whereas map can have like uh keys and values that are all kind of like you can have as many as you want a lot of times map string string is a very powerful thing because it's like agnostic and you can create all sorts of interesting data with that uh we're going to go deeper into all these topics so don't worry about it but first first off let's let's get into gra uh to additive versus non- additive Dimensions okay additive versus non-additive so this mostly is when you're talking about how to count stuff you are able to essentially take the sub counts and you can add them all up like all the all if you take all the sub totals and sum them up you get the grand total and you get the correct number number so like for example in uh the us if you take all the Oney olds plus all the 2y olds plus all the threey olds plus all the d d d to all the 115 year olds da da da and you add all of them up and like you take and you just and you just know the size of each group you know that you can just add all the sizes of each group together and then that is the correct number for um uh the grand total but not all dimensions are like this uh for example like uh I like this example around cars so say you have the number of Honda drivers the number of Honda drivers is not equal to the number of Civic drivers plus Corolla drivers plus Accord drivers and um the reason for this is because what if what if I own a Civic and a Corolla right then the problem here is I'm going to be double counted because I'll be a Civic driver and a Corolla driver I'll be in both buckets so but like you don't want to double count me I I I'm just one Honda driver I shouldn't count as two Honda drivers there whereas like if you slightly tweak this right instead instead of the number of Honda drivers you say the number of Honda cars then you're fine because a car can't be two cars at the same time but a driver can be two a driver can drive two different cars at the same time or in the same day and so like that's the essence here of additive versus non-additive is can a can a can can a an entity have two dimensional values at the same time over some sort of time frame and that is going to make more sense as we go deeper into this okay so the essential nature of additivity a dimension is additive over a specific time window if and only if the grain of data over that window can only ever be one value at a time this is like I know this sounds very like mathematical very like even got the if and only if in there you know the by conditional statement so um for example like say we go back to the Honda example so on a small enough time scale you could say that the number of Honda drivers is equal to the number of like Civic plus Corolla plus that right because imagine if you looked at just one a slice of one second right and then in one second like I can only be The Driver of one car I'm either going to be a a Honda a driver or a Civic driver but got a couple of questions here hi are you shifting your data your career to data engineering no not specifically like I still want to be a software engineer however um there have been projects where it'd be really useful for me to know more of the data engineering side because in my department they don't make a diff distinction between software engineering and data engineering um and so it it'd be really useful to hopefully be like leading a little bit more on some of those projects especially since it's an area where like we're heavily invested into uh we're heavily invested into Ai and data analytics and working with a lot of data different customers and a lot of it comes down to having to transform the data to make it \[Music\] um be queried well so I much prefer the data engineering side to the data and analytic side so um and the data and platform side as well uh so that's why I really want to learn it basically and then Matty yeah thank you for thank you for joining um thank you for coming to say hi yeah um it's definitely been it's been fun um and it's nice it's kind of like um having like a body double like by by putting this live because I've got people keeping me accountable because I'm making sure that I'm doing it live but I'm not going to be B Because unless I'm like able to like switch cars in one second which is probably not going to happen so uh on a small enough time scale uh that Dimension is additive but once you get it to a big enough time scale it no longer is additive and so that's a big thing to remember here is like how these Dimensions interact with time that is a big deal on like how how to uh think about the nature of these as you Aggregate and roll these up so that's the like this problem comes into a place in a couple places um one of the one of the key things that oh yeah it's on the slide cool so um how does additivity help so how additivity helps is if you have the subtotals and you know if you know the dimension is additive and you have the subtotals you can just add them up and you don't have to use count distinct cuz if you have to like if you're trying to do it uh the the grand total and if the the dimension isn't additive then you have to go back right you have to essentially do account count distinct over the entire data set as opposed to the subtotal data set you have to essentially go back you have to go down a layer you can't you can't have that a partially aggregated data you have to go all the way back to like the row level data to get the grand total because you don't know how much of the data is being overlap between like you know the the Civic and Corolla drivers is it one is it two like how much how much overlap are we talking and so one of the things that's interesting here though is this really only applies if you're aggregating a with a count because if you're aggregating a sum like for example if you instead you're saying the number of miles driven by Honda drivers then you're fine because you can say the number of miles driven by Honda drivers is equal to the number of miles driven by Civic drivers plus the number of miles driven by Corolla dri drivers and it all adds up it all makes sense right because I can't drive a mile in two cars at the same time unless I'm like I mean unless I'm like freaking Superman and I'm like like I'm like steering one car with my feet and like steering the other car with my hands right and doing some crazy like I I I mean for all intents and purposes we're going to say that that's not possible right so really additivity and this this nature only really matters for count but because it matters for count it also matters for other types of metrics as well right and the big other type of metric that it applies to besides um uh count metrics is when you have a ratio metric right so imagine you have uh the number of miles driven per driver then you're back to a metric is non additive right and you're going to have to like deal with it right if you compose these metrics together then you're still back into the nasty additive versus non-additive thing where you have to worry about count distinct versus not count distinct so remember the key thing here when uh you're looking at these Dimensions to know if they're additive or not is can a user be two of them at the same time in it usually like like hi how do I pronounce your name is it mon cool time here is like can user be two of these at the same time in a given day and if they can then it's not additive and you have to deal with it spe you have to deal with it you have to do deal with it differently you can't do like the partial aggregations like you can with other dimensions good news is is like most dimensions are additive uh like I would say there's only a couple usually these dimensions are going to be like a like I like to think of it like a tool right it's like a a user's tool right another great example is like you can't say the number of users on your app is equal to the number of iPhone plus Android users because of the fact that there's some people out there that are on both iPhone and Android and so it's like you see how that's like a a user's tool just like a car is a a user's tool you can something that a user uses and you can aggregate along that Dimension and that's why you get two values so that's definitely something to think about when you are uh doing these aggregations and like I like this was such a big at Facebook that like we actually built Frameworks around this so that people didn't have to worry about this problem anymore and that like if they wanted to do a non additive aggregation they can do it like efficiently through our frame thanks for joining M nice to see you to be fair I did um but you've just reminded me that I needed to speed it up so I'm going to do that right now I like thiswork and that was uh we built this thing called Milky Way and like yeah that was a painful little process that I noticed that I uh like this problem will show up so definitely just like do more research on this we're not going to cover much more about this in the lab but this is an important topic in terms of analytics and growths especially like user counting uh in growth analytics this is a very important topic to to consider all right so we're going to shift gears kind of completely here so we have um enums right so we covered enum in the last class remember the NBA scoring class like uh like Star good um average bad like we had those kind of different uh enumerated fields that we were working with uh there and one of the things that uh you'll notice with enumerations is there is a limit like to how like like how much you want to enumerate like and I love country country is always a great example because country is one where like uh some Junior data Engineers might be like yeah we should throw country in an enum and it's like n dog that's too many that's too many that's like 200 like I always think of Like A good rule of thumb here is like is it less than 50 right if it's less than 50 it's probably a good idea right uh that's where um we're going to be covering how enom could be very powerful in different data architectures in this um class as well let's go to the next slide so why should you use enums so a couple reasons one is you get built-in data quality for free essentially CU if you model a field as an enum if you get a value that doesn't the fit in the enum then the pipeline fails usually the pipeline will fail because it's like uh we're trying to cast this value to this enum and it doesn't exist so you get very good data quality in your pipeline like automatically um other things that you can get is you can get builtin static Fields cuz sometimes there's fields of an enum that are just static uh that you to know about right uh for example like in unit economics uh like I had an enum for all of the different line items and one of the static Fields was was this a revenue or a cost and that is just like okay each line item like fees are a revenue right and coupons are a cost and there's like all sorts of different like uh like like static fields that you can also apply to enums and the good thing about those is you can bring those in in a more efficient way than even like uh like a like a join like a broadcast join because the fact that they're just like in the code already and it's like you can just bring them you can ship you can ship enom and all the static Fields with your code so like it can be very very powerful way to do it and another big thing is is you get built-in documentation because now if you if you have a list and you know what all the possible values of that list can be that is another really great thing because that shows people like hey I know what are the possible values here and I know what I can do and um whereas like if it's a string that you don't get that right you don't get the the possible values when it's a string and and so um that's another great thing you get is built-in documentation so enom can really uplevel your data quality uh keeping in mind that you don't want to just throw it on anything like you want to make it so it's like if it's something that has 50 or less uh possible values that's like a good rule um like for example one of the enums that we had at Facebook was uh in notifications there was um we had this thing we had this notion of a channel a channel was like how we sent someone a notification which was like either SMS email or push and uh there was like one more there's also one that was like logged out push which is like a different Channel cuz some people um like in De in the developing World they actually share phones and so they get like Facebook actual things set up where you can get notifications when you're logged out for a different user uh because if you have someone who's like sharing a phone and that actually like really help increase engagement uh um in notific or like in for Facebook in the developing world but like when you think about that from like the United States perspective you're like whoa that's crazy that's like a crazy uh like we would never do that in the US right that sounds like a privacy concern or something like that but like different countries have different expectations there especially like when they're like sharing a phone but uh so anyways enom enums are great and they can model things really cool um so one of the amazing things that can happen is with enums is they can be a good value for your subar so say like in notifications again like when I was processing notifications like you don't want to process all the notifications together because it's like a lot so instead of just partitioning on date we partitioned on date and channel so there was also the channel column there which was and that's why enums are so powerful because if you have the exhaustive list of all of the possible values for a partition then you can build a pipeline that covers everything and waits and actually gets all the possible values and it doesn't miss any data and that could be another really great thing to remember when you're like working with the stuff so when I was like doing like my notifications ddop work uh that that was the case where we we essentially dup notifications by channel so that we could do them more in parallel as opposed to having to D all the notifications together and that can be a very powerful thing especially if you move up a layer and you are pushing this into uh like the logging layer as opposed to in your etls because then what you can do is if y'all have ever heard of thrift Thrift is a very powerful thing that you can use so Thrift is a way to manage schema in your logging as well as your etls and you can share the schema across the board and you can share enums you can share all sorts of different things through Thrift and uh that that's a very powerful way so that like the logging and the pipeline are on the same page in terms of what the enum values are because sometimes the enum values will change right you'll add one right or you might even remove one right and depending on the the case and the circumstances so that's a very powerful thing to think about uh this other big thing I I'll share these slides after this but like uh I came up with this design called the little book of pipelines that is a very uh it leverages this concept of enumerations uh to a great extent and this design I've used a bunch of times I used this design at Netflix to do like the asset inventory stuff and at Airbnb to work on unit economics essentially like this enumeration little book of pipelines uh pattern if you ever have a a pipeline that you're working on that really pushes that V of the variety V where there're like wow like this pipeline has 50 Upstream data sets like how do I manage all these data sets that's when you want to group those data sets into an enumerated group so then you have like uh all the groups that could possibly run and then that is how you keep track of all the possible values of stuff and that is uh what the little book of pipelines actually ends up doing and uh we're going to talk about that more on the next slide here let's talk about how this works um so you have uh a source all these different sources here so imagine like these like there was not just three you can have and number of sources this essentially Works uh kind of infinitely so what this does is you have an enumerated uh value right um that has some sort of uh um uh set of values here like for example at Airbnb there was like maybe fees and coupons and um infrastructure cost and all the different things that impact profitability and those all go down the the side here and you have all the source data that you get that from and then how it works is this enum gets pushed into these Source functions all it gets shared with all the source functions and then these Source functions what they do is they map the data to a shared schema and the way they do that is this shared logic ETL will call The Source function and then it will map it over into the shared schema and then then after that the little book of enums also has the data quality checks for that enumerated value because your data quality even though now the schema is shared that doesn't necessarily mean that the data quality check should be shared because like what is anomalous for fees and what is anomalous for coupons is probably different and so that can be a very big difference that you can think about and that's where this little book can be very powerful because it what it stores is it stores all the enumerated values all the data quality checks and then but then it makes it so that like even if you have a shared schema you can have customized data quality checks on on each partition depending on whatever's in that little book and then after the data quality check fast then you have your final sub partitioned output and this partitioned outbut will have like it'll have a date partition and then it will have a subpartition which is this enumerated value whether that be like a like you know fees coupons or something like that like some sort of enumerated list of things that could possibly be in here so this pattern works at like especially if you have a massively large ETL that like covers a lot of different topics and like and they all need to come together into one shared this is a very very powerful design that I've noticed that really makes it easy to keep track of things because then if you need a new source you just add another value to the enom done easy right and then and then you get your DQ checks and then you just have to add the source function and then everything else will just work and then it all is very cohesive and integrated and I've noticed that like when you implement this pattern what happens is the the quality of these pipelines goes up dramatically and you get uh and you also get this documentation for free because now people can be like oh what are the possible part partitions in here and you just query the little book here and you're done right and it's pretty great um so how that little book actually is generated right so it's usually going to be an En an enumeration defined in either like python or Scala but then what you you have a job that essentially turns that enumerated uh list into a table and that table will be tiny it'll be maybe like 20 or 30 rows or 40 rows however many values in the enum you have and then that's how you can share it between like your DQ checks and your Source functions where in the source functions you pass it as python and then in the the DQ checks you pass it as a table and you join and that's how you get like your thresholds for like week over week month over month stuff like that that uh and keep in mind that like uh there's a lot going on with this pattern and so like I highly recommend that y'all check out this example there's some it's it's a it's an open source uh library that I um or open source like GitHub repo that I I shared that y'all can check out after this um presentation uh so let's uh go into this a little bit more so like what are the use cases for this little book at Eno so I've seen it happen a couple different times right earlier I was talking about uh Airbnb they have unit economics where it has all these enumerated Fields fees coupons credits insurance and infrastructure cost taxes uh referral credit there's so many more and then uh Netflix also with the infrastructure graph that I worked on in that case you have like applications databases servers codebases cicd drops you just have this like big list of things that you need to put together and that's kind of the idea behind this this pipeline design is that if you ever have this like I call this like large scale like data integration when you need to like just bring tons and tons of data together into one table and then also this I saw this at Facebook as well for the family of apps where in that case like Oculus Instagram Facebook Messenger WhatsApp and probably threads now I don't know if on thre you should definitely follow me on threads I post some spicy memes on thread it reminds me a little bit of a project we were doing recently um and we had multiple dat sources uh but we were using um data bricks in uh what it dat books yeah date books uh we was in dat and um but we didn't use enums for the the value of the sauce but we did track the sauce but I can see how spe creating an enum for it would have been better to be fair we just had the the sauce is a table um but yeah it probably didn't we just had a table with the list of the names of the sources um and and I next to them but yeah I can see how we could have just been do with them so uh those are kind of the um use cases right that I've seen in my career and they're they've all been very impactful all like change the company in some way or another so definitely uh I highly recommend checking this pattern out hi nice to meet you how do I um pronounce your name is it Delia sorry like I always try and make sure that I pronounce things properly because I I don't want to get it wrong basically it can be very very powerful okay so one of the things that I was talking about in this pattern though if you remember back here where we have that shared logic and that shared output what this ends up being is you end up having a pattern where all of the all the data ends up being in the same table um so how do you model data from disparate sources into a shared schema So It's Tricky uh and the main way that you do this is with what I call a flexible schema because like you don't want to just like bring in all the columns from all 40 tables and you just have like one table that has like 500 columns where most of them are null all the time because that's like not a very usable table right and you don't want to work with stuff that way that's definitely not the way that you want to like bring the data in what you want to do instead is you want to work with what I call a flexible schema and this flexible schema is where you're going to be leverage a lot of map map data types here it's going to be the big one that you use to do things and a lot of this stuff is going to overlap a lot with uh that kind of graph you know that graph database I was talking about because the enumerated list of things is very similar to like in uh in the in the graph database world we have this thing called a Vertex type right and that is very similar because it's just like an enumerated list of types and so these these concepts are integ integrally connected and so like let's talk more about flexible schema so uh flexible schema is awesome because if you need to add more things you just put it in the map uh which is great just throw more columns in the map like if more columns appear you just throw them in the map uh that's awesome that's a great um and then the map can just get bigger and bigger and bigger uh there is a limit right I think Maps like in like spark and that world I think they can have like 65,000 Keys like so so there is a limit there actually is like a fundamental limit but like I've never had that many keys in my map I I've maybe had like a thousand keys in my map at one time but like never like 65,000 that's like a it's an aggressive amount of keys so that's like uh and that limit comes from the like the bite length or some sort of java limit right um so you can manage a lot more columns when it's flexible right because you can just add another key to the map and you don't have to run alra cable it's great uh you don't have all these null columns because a lot of times like with flexible schemas it's just going to not be in the map and so it just doesn't show up um another good thing that I've seen a lot of like companies do is they have this column called like other properties where if you want to bring more columns into the table that are probably not going to be queried that much so you don't actually want to do the modeling of them because like why bring them in and get all these weird questions about like what does this column mean like what they do instead is they just throw it into other properties they call it a day um really great um obviously flexible schema if like it was all good then we would just be using flexible schema for everything uh it's not all good um a very big drawback is compression so if you throw everything into a map uh maps are going to be uh pretty much the worst compression of all the data types um the only thing that might be worse is Json Json and maps are both really terrible they both are like very huge and they don't they don't squish down very well because and the main reason for that is that you got to think about it like where um in the old world like if you have a a column header for every column that's great but and then the the column header is only listed once but if you put it in the map now the the the header is in every single row so and that's stored as data so the header is now data instead of being just part of the schema and that is one of the things that really greatly increases the size of the map and the flexible data types so definitely um think about that when you're trying to work with this stuff so yeah how is graph data how is graph data modeling different graph data modeling is relationship focused it's not entity focused so like a lot of these columns and things like that that you would find in data tables are just freaking not there uh like the I'm about to give you the super secret sauce to all graph data modeling I hope yall are ready for this it's it's very very easy because every graph database I've ever I've made like probably three or four graph databases now in my and they all have the same sche all and it's weird it's like spooky how they all have the exact same schema so like just if you can remember this schema then like you'll like you you you essentially have your graph data modeling skills mastered so um the main thing to remember about graph data modeling is that it's not entity focused so we don't care about columns we really don't so really for an entity in a graph uh you have three columns you have an identifier you have a type and and then you have properties of that um of that uh vertex right or that node and so um in this case like in our examples today that we're going to be working on we're going to have a type which is like a player type and the identifier will be their name and then in the properties might be like their height or their weight or their draft year and things like that so definitely to I found the same even like you know I'm thinking about like what we're just going through at the moment and in one of the projects we did I did run into that issue of where when we were bringing in the Raw data there was a lot of colums that were were null um so using a um flexible schema might have been better cuz we were bringing in data like every day on like a schedule and it kind of went into the the Raw file like the the raw data first and then we transformed it to to so that the columns matched but yeah I can see how this would been usful be working with some of those and we will be uh building that out but keeping in mind that like this schema is exactly the same for uh like the family of apps right for example like you would have a user ID and then it would be of type user and or it might be a type WhatsApp user or type Instagram user and then you have a Gra that maps all of these properties over to each other how they're connected because maybe this Instagram user actually has a connection to that WhatsApp user because they're the same person and there's a relationship between these two nodes and that's what we care about yeah no same I've had to also Google a few things just to understand what they mean a little bit more like um lag I think was the one from the previous I had to to Google what that meant and then um yeah just a few different things where it was like okay well is I get what you know what he's telling me is doing but what is this specific part doing um I had to do a little bit of that last week we care about the relationships we don't care about the entities themselves as much and that's like the whole idea behind graph databases is like it's Shifting the focus from how things are to how things are connected and if you can remember that you're going to do a lot better in your graph data modeling uh experiences so yeah let's go to the next slide okay so in that case remember um uh for uh vertexes you have that three column schema um edges have their own uh schema which again is pretty much standard this schema is very standard where you have your subject identifier subject type object identifier object type Edge type and then properties of that relationship like for example like um like the edge type the edge type is almost always like a a verb like it might be is a or plays with or has a or different things like that it's like it's like a very it's like like like a like one or two word like sentence it's a very simple thing that like connects things like for example in the lab today we're going to look at like how players in the NBA play with each other and against each other so you have like plays with and plays against those are two different uh columns that we are going to be generating or two different Edge types that we are going to be generating in today's lab uh and so if you look at the different things here like I like to think of subject and object as like like a sentence right where the subject is the person doing the thing and then the object is the thing that's being the thing is being done on like right like for example we are also going to be creating a relationship between a player and a team so it would be like um it would be like player plays on team and so in that case you would have the ident the subject identifier would be a player name the subject type is going to be player the object identifier will be a team name the object type is a team and then the edge type is plays on or like that's going to be the they play on that team and then the properties might be like how many years did they play on that team when did they first start playing on that team things like that right there'll be these different properties of that team object that we'll be working with so that's kind of the idea behind um edges so you have nodes and you have edges and they are connected right the way they're connected is an an Edge takes two nodes and links them and it links them through some sort of type some sort of edge type and then they're linked together that's like that's the whole point of graph databases is looking at how things are connected so let's look at an example here real quick so in uh we're going to be building out this exact graph database in the lab today but you'll see um like you have you have like Michael Jordan and John Stockton these are two like kind of famous NBA players who play against each other in like the 1990s in the NBA finals and uh they play against each other because they're on different mes but then you'll see that like John Stockton is connected to the Utah Jazz because he plays on the Utah Jazz and so this is exactly what kind of modeling you're going to expect when you are building out graph databases is you have uh like you have your subjects you have your objects you have your connections and then they might have properties inside of them but this is the idea is like you're really focusing on how things are connected and this is how you can build out these kind of models and like you can build build out really really cool insights from this CU a lot of the stuff like when you are in the other world when you're in that kind of like relational database world and you're not in this graph World a lot of the times like the queries that you're trying to do like these graph traversal queries they get messy because like you have to join and you have to create all these like crazy joins to like do it you have to bring all the vertex data together and do all these like crazy extra scans but like once you get the data in this format then you can start traversing the graph and seeing how things are connected in a lot more of an efficient way and that was a big thing that like when I was working in Netflix that was a big thing I worked on was like how do I get all of these different entities into a singular graph database that then people can query and people can like look at and that was uh yeah it was fun it was a really fun problem but also a very challenging problem because it just gets super messy but that's kind of the idea behind how graph databases kind of work all right so I think that's pretty much uh it for the the slides \[Music\] today um that's interesting I've not worked much I've not I've not worked with gra databases before to be fair um I I do wonder if we're going to end up doing some sort of like topological Sal or like like you know shortest path algorithms are we going to start doing some grath DSA style problems in in SQL I don't know um it's an interesting I think I think it was quite a theoretical video so I'm looking forward to um I'm I'm looking forward to actually getting into the lab tomorrow and being able to see what like that actually means because at the moment it is quite theoretical for me and then I just want to see it a little bit more before um before I go more into it so I'm going to end the video there like I said I thought it was quite a short video to be fair and there wasn't a lot of graph database information I suppose the title does say additive Dimensions as well so that's fair enough um I'm just going to check my thing is registered say 65 67% I'll check tomorrow but um yeah yeah I definitely hope the lab gives me a little bit more clarity on how you would then use uh use the graphs within a database because at the moment it's a little bit theoretical for me but yeah that is it I am done and thank you for watching for those who are watching I will see you tomorrow and yeah just interact a little bit more maybe um tell me what your favorite um meal is or something um just just to make it a little bit more um fun and so that I don't have to be socially awkward as I currently am thank you everyone thank you for watching I will end there and I'll see you tomorrow if you are here tomorrow bye


 > [!info]
> - **Additive vs. Non-Additive Dimensions (7:05):** Understand when subtotals can be added to get the grand total. Non-additive dimensions require count distinct, needing row-level data.
> - **Additivity and Time (11:34):** The additivity of a dimension can change based on the time scale. What's additive over a small time scale may not be over a larger one.
> - **Impact of Additivity (12:13):** Additivity matters for count and ratio metrics. Non-additive metrics require count distinct, impacting aggregation strategies.
> - **Enums for Data Quality (17:01, 17:56):** Use enums (enumerations) for built-in data quality and documentation, but limit the number of values (ideally under 50).
> - **Enums as Sub-Partition Keys (20:39):** Enums can be powerful for sub-partitioning data, ensuring exhaustive coverage in pipelines.
> - **Little Book of Pipelines Pattern (22:13):** This design leverages enumerations for managing pipelines with many upstream data sets, improving data quality and documentation.
> - **Flexible Schema with Maps (28:50):** Use flexible schemas with map data types to model data from disparate sources, but be aware of compression drawbacks (31:15).
> - **Graph Data Modeling (32:07):** Shift focus from entities to relationships. The key is to identify subjects, objects, edge types, and properties of relationships.
> - **Standard Graph Schema (32:46):** Vertices have an identifier, type, and properties. Edges have subject/object identifiers and types, edge type, and properties.
> - **Edge Types as Verbs (36:04):** Edge types are often verbs describing the relationship between nodes.
> 